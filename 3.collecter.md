# Collecter

## Contexte
Cette phase du cycle de vie de la donnée, concerne le recueil et la constitution des jeux de données avec leur métadonnées. 
Il s'agit de travaller à l'acquisition des données au moyen de divers media (capteurs environnementaux, sondages...)  selon le domaine étudié, pour constituer des jeux de données, et les décrire avec leurs métadonnées associées. 
Il faut pour cela choisir des référentiels (thésaurus) les plus appropriés selon le domaine étudié.

Les jeux de données  sont alors gérés dans un environnement technique leur permettant d’assurer le stockage, le «versionning», et l’accessibilité des données et des jeux de données 
via des bases ou des supports fiables et bien documentés, dans le respect des règles de traitement spécifiques des données personnelles.

Cette phase nécessite d'étudier :

   * la nécessité de metadonnées précises pour la description des capteurs de mesures et des dispositifs d'acquisition
   * l'établissement et la documentation  des chaines de collecte : du capteur jusqu'aux disques et aux serveurs où les traitements pourront être établis
   * la nécessité de gestion et la conduite de projets pour faire travailler ensembles différents acteurs intervenant dans la chaîne de collecte : électronicien, informaticiens, chercheurs
   * la nécessité de disposer de cahier de laboratoire, tablettes de terrain ou supports divers pour consigner les relevés et métadonnées observées 
   * l'utilisation de protocoles si possibles normalisés ou standardisés pour présenter les données de capteurs et les rendre interopérables
   * le stockage nécessaire à la collecte de données : travailler en amont avec une équipe informatique en mode projet (gestion de projet)


## Assurer la traçabilité des données 


   * Savoir anticiper les nouveaux outils, les technologies émergentes en matière (ANF 2016)
   * <https://indico.mathrice.fr/event/5/contribution/3/material/slides/0.pdf>

***   * Normes et standards (***proposition GR )


   * ANDRE, François, 2014. Normes OGC. In : *ANF2014 DEVLOG-RBDD : Infrastructure de Données géographiques et Spatialisées 
    * <http://devlog.cnrs.fr/\_media/ids2014\_presentationogc\_francoisandre.pdf?id=ids2014\_j2\&cache=cache>
ATTENTION LIEN CASSE !

**Activités de recherche et gestion des connaissances**

* Activités de recherche et gestion des connaissances 
* <https://anfdonnees2016.sciencesconf.org/data/pages/donnees_renatis_Al1_Rivet_2016.pdf>
* Vidéos : 
	- <https://youtu.be/UhBwjJDQcdg>
	- <https://youtu.be/6IaYJ_Rvm28>
	- <https://youtu.be/7apGMS9gg5g>
	- <https://youtu.be/Ld5vEByAMNA>
	- <https://youtu.be/wVgQ_2fM10s>

Alain Rivet présente la **problématique de la donnée dans la perspective de la traçabilité des activités de recherche** (contexte et enjeux). Il pose la **question du  
défi organisationnel  de la gestion des données dans les laboratoires et les établissements face aux contraintes de plus en plus fortes des autorités de tutelles**

 – Il souligne le **besoin d’optimiser le fonctionnement de nos laboratoires, la solution étant de s’appuyer sur des référentiels**.
Il introduit la **notion de qualité en recherche** qui consiste tout simplement à répondre à un besoin de recherche. Il insiste sur la **nécessaire confiance en la 
qualité d’une recherche qui suppose une maitrise de l’ensemble des moyens d’acquisition de traitement, de diffusion et de conservation des résultats**.

La présentation contient une **liste des référentiels** **intéressant les unités de recherche** et les fascicules existants,  L’ISO 9001, norme généraliste définit 
le management de la qualité – OCDE et bonnes pratiques de laboratoire etc.

Il aborde le sujet *d'une démarche qualité* au service de la gestion des données dans les laboratoires en précisant qu’il ne suffit pas qu’une donnée soit riche en métadonnées 
pour que ce soit une donnée de qualité. Il faut avoir une maitrise des différentes étapes qui produisent la donnée pour garantir une donnée de qualité. 

Il ajoute que les **aspects organisationnels et qualitatifs autour de la donnée ont nécessairement un impact sur la qualité de la recherche**. On constate de plus en 
plus la limite de l’évaluation par les pairs pour garantir la qualité d’une recherche (exemples de fraudes et scandales médiatiques) 

–Il y a toutefois une prise de conscience des tutelles de ces problèmes qui mettent en place une stratégie nationale avec la rédaction début 2016 d’une charte de déontologie qui insiste sur 
l’importance de permettre la traçabilité des travaux expérimentaux. 
La présentation comprend un **éclairage sur une fiche projet type en chimie qui retrace le processus simplifié d’une recherche et répond aux besoins de traçabilité 
des activités de recherche**
En conclusion, il signale l’importance de développer une démarche qualité comme outil de gestion des données : la qualité étant un outil, pas un objectif, 
c’est une norme organisationnelle qui est peu contraignante.


Le réseau Qualité en Recherche a élaboré un guide «* Traçabilité des activités de recherche et gestion des connaissances *», à destination des unités de recherche.
Il a comme objectif de fournir des recommandations et bonnes pratiques pouvant être appliquées dans tous les domaines d’activités, tant administratifs, techniques que scientifiques, 
afin d’assurer la traçabilité des activités de recherche et d’améliorer la gestion des données de la recherche.
<http://qualite-en-recherche.cnrs.fr/IMG/pdf/guide_tracabilite_activites_recherche_gestion_connaissances.pdf>

 

### Traçabilité des données et bases de données

* Présentation générale sur la problématique de la traçabilité des données appliquée aux bases de données, Marie-Claude QUIDOZ, 2018
* <http://rbdd.cnrs.fr/IMG/pdf/atelier\_tracabilite.pdf?523/29abaadfb5e2e0fff8aed53afd88d7aad1ded34f>

Cette présentation synthétique présente les différentes facettes de la traçabilité d'un jeu de données. 

* E-Maj comme "Enregistrement des Mises A Jour" : Et vos données PostgreSQL voyagent dans le temps ! Un cas d’utilisation pour tracer les données PostgreSQL, Marie-Claude QUIDOZ, Philippe BEAUDOIN, 2018
* <http://rbdd.cnrs.fr/IMG/pdf/emaj.2.3.1\_overview\_fr.pdf?521/c82f6d6408a4f4848d9792a0ab3715a09b5eea5f> et <http://rbdd.cnrs.fr/IMG/pdf/tp\_e-maj.pdf?522/cbfcf7b13ae9a4d8d20ec495c1ef5ea1d09e0a3f>

Cet atelier rBDD dont sont fournis ici les liens vers les transparents des présentations, permet de découvrir E-Maj. E-Maj est composé d'un client web « Emaj_web » et de l’extension PostgreSQL « E-Maj » sous licence GPL.

E-Maj sert à :
- Déplacer dans le temps des contenus de données, avec une
granularité de niveau table 
- En enregistrant les mises à jours sur des ensembles de tables applicatives, on peut : 
    - les dénombrer,
    - les consulter,
    - les annuler,
    - les rejouer.

E-Maj est utilisable avec :
    - des applications en test ou en production,
    - des bases de données de toute taille.
  

## Maîtriser l’acquisition et la collecte des données

Différents aspects de collecte de données existent qu'ils proviennent d'un équipement, d'un capteur automatisé, par un modèle numérique ou qu'ils soient obtenus par un personnel de terrain, par une enquête, au moyen d'interfaces... 
Dès lors, il convient d'élaborer des méthodologies de collecte, de conseiller quant au choix des référentiels de métadonnées (et thésaurus ?)
de développer les procédures d'intégration des données dans les bases...

### Les données personnelles

Le Règlement Général sur la Protection des Données (RGPD) est une modernisation fonda-mentale des lois européennes sur la protection des données qui place l’idée de confidentialité comme droit fondamental des personnes. 
Dès lors que l’on va collecter des données personnelles (données permettant l’identification directe ou indirecte d’une personne), il sera important de respecter des principes essentiels sur la durée de conservation des données,
le droit à l’information et l’obligation de sécuriser les données. Il ne faut pas hésiter à se rapprocher du correspondant du Délégué à la protection des données (DPD) de votre délégation (pour le CNRS) ou du Délégué à la protection des données de votre établissement.
Prise en compte des données personnelles - Évolution de la règlementation : <https://qer-2017.sciencesconf.org/data/program/2017_ANF_tracabilite_guillot_1.pdf>



### Cahiers de laboratoire 

L’ensemble des données produites par la recherche doit ainsi être répertorié et enregistré dans l’objectif d’une réutilisation potentielle. Nous disposons pour ce faire d’un certain nombre de supports comme les cahiers de laboratoire. 
Le cahier de laboratoire est un outil non obligatoire mais fortement recommandé pour toute structure générant des données donnant lieu à des connaissances diffusables et valorisables.
Il constitue un véritable outil scientifique et ce, dès le commencement d’un projet.
[<https://qer-2017.sciencesconf.org/data/program/2017_ANF_tracabilite_denis_meyere.pdf>](<https://qer-2017.sciencesconf.org/data/program/2017_ANF_tracabilite_denis_meyere.pdf)

Les plaquettes "Le cahier de laboratoire national : Pourquoi l’utiliser ?" et "Le cahier de laboratoire national : 
Comment l’utiliser ?" (<https://www.curie.asso.fr/-Cahier-de-laboratoire-national-.html>) présentent des recommandations sur la bonne gestion de ce dernier. 

Les cahiers de laboratoire électroniques présentent plusieurs avantages qui intéressent les unités de recherche : 
-	le partage de l’information avec un rattachement des données brutes ; 
-	une recherche d’informations facilitée ;
-	une datation assurée des expériences par l’horodatage.

Le site [datacc.org](datacc.org) consacre la mise en œuvre d’un service d’accompagnement sur la gestion des données en physique et en chimie, dans le cadre d’un projet CollEx-Persée. 
Le site fournit également des contenus nourris sur les cahiers de laboratoire électroniques (<https://www.datacc.org/bonnes-pratiques/utiliser-un-cahier-de-laboratoire-numerique/>), issus d’une expérimentation menée avec des chimistes de Lyon 1 et de Grenoble.

Diverses expérimentations ont également été réalisées :

   * Expérimentation du cahier de laboratoire électronique à l’Inserm  :  <https://qer-2017.sciencesconf.org/data/program/2017_ANF_tracabilite_dupre.pdf>       
   * Utilisation du cahier de laboratoire électronique BIOVIA au sein de l'Institut de Biologie Structurale : <https://qer-2017.sciencesconf.org/data/program/2017\ANF\tracabilite\laguri.pdf>
   

### Tablettes et carnets de terrain

 Les données et documents produits directement sur le terrain témoignent de l’activité de recherche dans diverses disciplines, notamment en sciences humaines et sociales, en sciences de la terre... 
 Il s’agit aussi bien de carnets issus d’entretiens de sociologues, d’ethnologues, de carnets de prélèvements en géochimie, géologie, de carnets de fouilles en archéologie, de notes, de photographies prises sur le terrain… 
 Certains sites peuvent aujourd’hui être des terrains de guerre et seuls les documents produits lors d’une mission restent utilisables pour la recherche actuelle et future. Il est de ce fait essentiel que ces données soient répertoriées et archivées. 
 L’utilisation des tablettes pour consigner les relevés et métadonnées observées permet de profiter des avantages de ces appareils nomades. 

   * AKOUETTE, Ata Franck, 2018. Collecte de données terrain avec un smartphone : Prise en main de Kobotolbox et de Kobocollect. *FOSS4G-fr 2018*, Marne-la-vallée. 2018. <https://github.com/OSGeo-fr/FOSS4G-fr-2018/blob/master/ateliers/Atelier-kobo.pdf>

   * BORDÈRES, Serge, 2018. Pi 4x4 : Conception d'une tablette de terrain pour la recherche. In : *Atelier "carnets de terrain électroniques"* [en ligne]. Montpellier. 2018.<http://rbdd.cnrs.fr/IMG/pdf/borderes\_atelier2018.pdf?441/72f4dc952e0ac74b725a41d43bc28bb07ecdef38>

   * Retour d’expérience sur le montage d’une tablette PI4*4 (M. Rouan) (<http://rbdd.cnrs.fr/IMG/pdf/pi\_4\_4.pdf?578/687ae458554248a59a0359cc7f13b28fc2a602d5)>

   * Outils nomades : définir ses besoins. Tour d’horizon des applis embarquées et retour d’expérience (C. Plumejeaud, S.Ladet), 2019 
     * http://rbdd.cnrs.fr/IMG/pdf/anf_rbbd_2019_outils_mobiles_cours-besoins_2juin2019.pdf?577/a94b104f974483c5dbda6c4939ef0db9422bd1dd

    * Carnet de terrain électronique, Retour d’expérience sur la création d’une boite à outils, Marie-Claude Quidoz (UMR 5175 - Centre d’Écologie Fonctionnelle et Évolutive), 2015
        * transparents de la présentation : http://rbdd.cnrs.fr/IMG/pdf/carnet_terrain-rmll.pdf?134/71c86482f00d5bdfd436925df796213c837058d5
        * présentation orale  lors des 15èmes Rencontres Mondiales du Logiciel Libre en juillet 2014 : http://video.rmll.info/videos/carnet-de-terrain-electronique/
        Ce retour d'expérience détaille l'étude et le développement d'un ensemble d'outils interopérables avec le système d'information du laboratoire CEFE et qui permet aux intervenants sur le terrain de collecter les données.

       
       * Présentation de la solution ODK (MC. Quidoz) (<http://rbdd.cnrs.fr/IMG/pdf/deployer\_avec\_odk.pdf?569/9c7a0e508a744bc2ddd757184ad6427b9505b214)>

       *  Comment faire un formulaire avec XLSForm ? (PY. Arnould) (<http://rbdd.cnrs.fr/IMG/pdf/xlsform\_anf2019-2.pdf?575/d45519bbb0360384f14bcf6f4c072313eb7c60a5)>

       *  Mobile Atlas Creator (A. Cheylan) (<http://rbdd.cnrs.fr/IMG/pdf/mobac.pdf?572/f49254091f49630e2b2088ec36964cbd931e0278)>

### Les capteurs

### La gestion des collections

  * "Stockez et retrouvez vos échantillons avec Collec-Science, un logiciel web permettant de gérer les échantillons collectés lors des campagnes d’acquisition"
       * <http://rbdd.cnrs.fr/spip.php?article304>
       * contact : Christine Plumejeaud christine.plumejeaud-perreau@univ-lr.fr).  
       * Pour plus d’informations : https://www.collec-science.org

Collec-Science est un logiciel web qui a été créé pour suivre les échantillons collectés lors des campagnes d’acquisition, et permet de répondre, entre autres, à ces questions :
    -   où est stocké l’échantillon ?
    -   d’où vient-il, quelle est sa généalogie (protocole de collecte, métadonnées associées à l’échantillon et ceux de ces ancêtres) ?
    -   quelles transformations ou opérations a-t-il subi ?
    -   sous quelle forme est-il conservé, existe-t-il un risque à le manipuler ?

Fruit d’une collaboration initiale entre Irstea (centre de Bordeaux), le laboratoire Epoc à Bordeaux, le LIENSs à La Rochelle, il a été enrichi avec la participation de nombreux autres laboratoires, dont les laboratoires Chrono-environnement à Besançon, Edytem à l’Université Savoie - Mont Blanc, etc. Il a été choisi par le Réseau des Zones Ateliers pour assurer le suivi des échantillons.

   

## Environnements de stockage - Sauvegarder les données**

prévoir, estimer  le stockage nécessaire à la collecte de données : travailler en amont avec une équipe informatique en mode projet (gestion de projet)
 

   * Architectures de stockage traditionnels (ANF 2016)
   * <https://indico.mathrice.fr/event/5/contribution/2/material/slides/0.pdf>

## Structurer et organiser les données


### Choisir les référentiels de métadonnées (thésaurus, ontologies)

Utilisation de standards d'interopérabilité dans la gestion des métadonnées

Pourquoi un catalogue de métadonnées ?
Outil de diffusion / valorisation
Outil de recherche
Directive Inspire sur les données géographiques publiques (2007)–Catalogage des données–Accès gratuit aux métadonnées


   * Mise en place de catalogues INSPIRE et de leur alimentation automatique.                                       
       * <https://sist16.sciencesconf.org/data/pages/14\_C\_Bernard\_J\_Fabre.pdf>
           *   - Cyril Bernard, CEFE - Juliette Fabre, OSU OREME - Olivier Lobry, OSU OREME


**INSPIRE un cadre pour mieux partager les données de la recherche **
* Marc Leobet, Chargé de mission et PCE INSPIRE
* Frédocs2013 - Gestion et valorisation des données de la recherche -  7 au 10 octobre 2013, Aussois    
* http://renatis.cnrs.fr/IMG/pdf/Leobet_INSPIRE_Fredoc2013.pdf

Cette présentation réalisée en 2013 par Marc Leobet , chargé de mission à la Mission information géographique du ministère en charge du développement durable pose 
le **cadre de la Directive Inspire**. Il présente tout d’abord l’**utilité de cette Directive** (identification des données, gestion de la confidentialité, des problèmes 
de conventionnement  et qualité des données), son **contexte**, les **obligations qu’elle induit**, le contexte autour de la **réutilisation des données du secteur public et 
l’application de la Directive inspire dans le domaine de la recherche**
 (partage des données et diffusion des métadonnées)
  

### Utiliser des Standards d'interopérabilité


#### Utiliser des formats interopérables
(MCQ : ce n'est pas forcèment dans le collecte que l'on fait cela car on collecte souvent avec les appareils dont on a besoin pour sa science)


 *Format et métadonnées*


* Catherine Morel-Pair , INIST, CNRS
* ANF "Participer à l'organisation du management des données de la recherche : gestion de contenu et documentation des données" -  6-8 juil. 2016 Paris (France) 
* Vidéo -    https://youtu.be/obGDFrXyBiU?t=3
* ppt - https://anfdonnees2016.sciencesconf.org/data/pages/2016_07_07_ANF_Renatis_Formats_Standards_et_Metadonnees_1.pdf

Catherine Morel Pair propose ici une présentation très riche et très complète sur les f**ormats et métadonnées** qu’elle détaille de manière très approfondie et restitue 
dans le cadre de **leur utilisation pour la gestion de contenu** **et la documentation des données**. Elle aborde en introduction les notions de données de la recherche, de 
Fair Data, d’intéropérabilité et de Data Management Plan. La première partie de sa présentation porte sur les **fichiers de données (organisation et nommage, format et 
critères d’interopérabilité-pérénité)** la deuxième partie est dédiée a**ux métadonnées et à la documentation  (définitions, présentation des standards, des identifiants 
pérennes pour les données et syntaxes d’échange)**. Elle termine par un focus sur les sites de de dépôt, de portails ou d’entrepôts de données et leur schéma de 
métadonnées associés.

**Les métadonnées dans un DMP **
* Marie Puren,  INRIA  
* ANF "Participer à l'organisation du management des données de la recherche : gestion de contenu et documentation des données" -  3-6 juil. 2017 Paris (France) 
* https://anfdonnees2017.sciencesconf.org/data/pages/20170706_dmp_metadonnees_puren_1.pdf 

Cette présentation très riche de Marie Puren a été conçue pour animer un atelier de formation qui avait pour objectif de **définir et comprendre l’importance des 
métadonnées dans le cadre de la rédaction d’un DMP**. Elle définit en donnant des exemples ce qu’est une métadonnée, à quoi elle sert, quelle information elle donne. 
Elle distingue et détaille la **spécificité des métadonnées de description, des métadonnées de gestion et des métadonnées de préservation**. Elle aborde ensuite le 
chapitre du **cycle de vie des métadonnées (créer, entretenir, mettre à jour, stocker, gérer la suppression des données, publier)**. Elle spécifie les **métadonnées à 
faire figurer dans un DMP**
, explique **comment les collecter** et propose quelques **outils d’extraction automatique de métadonnées**. Autour de la notion de métadonnée, 
elle précise l’importance de définir des responsabilités en s’appuyant sur les chercheurs, documentalistes, bibliothécaires et informaticiens. Elle complète sa 
présentation avec une description des **principaux standards interdisciplinaires et disciplinaires de métadonnées**. Elle explique **où et comment choisir ses standards**. 
Elle explique également l’**intérêt d’associer des ontologies ou vocabulaires contrôlés**. Les dernières recommandations de sa présentation portent sur la **gestion des 
métadonnées à long-terme**, l’importance d’**évaluer leur qualité** et revient sur la **notion d’ouverture des métadonnées** et la nécessité de **choisir des licences** pour nos 
métadonnées.
   


#### les standards de l'OGC en sciences de l'environnement

les gestionnaires de données environnementales mettent en place des chaînes de collecte de données provenant de capteurs de terrains, ou de modèles numériques. Ils se préoccupent de l’utilisation de normes interopérables dans les protocoles d'échange et dans les formats de données

Cette partie traite de l'Utilisation* des standards d'interopérabilité en sciences de l'environnement*

A cet effet l'OGC (open géospatial consortium) publie différents standards d’interopérabilité, dont *SWE* "Sensor Web Enablement", qui permet de présenter des données de capteur de manière standardisée et interopérable [à détailler]

Ces protocoles standards de l'OGC  ont été présentés lors du Séminaire du réseau  SIST2015 à l'OSU Pytheas de Marseille


   * Présentation des différents protocoles interopérables proposés par l'OGC
       * <https://sist15.sciencesconf.org/data/program/ogc.pdf>
           * François André OMP Toulouse

   * Présentation du standard "SWE" Sensor Web Enablement et "SOS" Sensor Observation Service
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
           * christoph Stasch co-auteur du logiciel "52North" présente les standards SWE et SOS et leur implémentation dans le logiciel "52North"
           https://nuage.osupytheas.fr/s/iMx5S9orQ9zyoxk 
           

Le programme Seadatanet vise à élaborer et mettre en place un portail Européen d'accès aux données marines. Il se base sur de nombreux standards rendants les données FAIR, cherchable, Interopérables et Réutilisables
Seadatanet est un exemple d'envergure pour la mise en place de standards d'interopérabilité à l'échelle Européenne. 
   * Présentation du projet *SeaDataNet, interopérabilité à l'échelle pan-européenne *
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
           * Michèle Fichaut, Systèmes d'Informations Scientifiques pour la MER                                                                                    


   * Portail Web d'accès aux données de l'observatoire AMMA-CATCH et mise en oeuvre des standards d'échange des données OGC  
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
           * Véronique CHAFFARD, Institut de Recherche pour le Développement, Laboratoire d'étude des transferts en hydrologie et environnement

   * SI-TEC-PSO: retour d'expérience sur le système d'information dédié capteurs et reconstitution de séries temporelles de ReefTEMPS, le réseau de suivi de température des eaux côtières dans la région du Pacifique Sud et Sud-Ouest 
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
           * Sylvie Fiat, et  Régis Hocdé, Institut de Recherche pour le Développement

   *  De la définition au déploiement de standards d'interopérabilité : retour d'expérience de la Direction des Systèmes d'Information (DSI) du BRGM
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
           *  Grellet Sylvain, BRGM - Stéphane Loigerot, BRGM        


   *  Le projet Dat@OSU de gestion et valorisation des données de la recherche   
       *  <https://sist16.sciencesconf.org/data/pages/13\_B\_Debray.pdf>                                      
           *  - Bernard Debray, Univers, Transport, Interfaces, Nanostructures, Atmosphère et environnement, Molécules                                                                                         


Le protocole SOS (Sensor observation service) de l'OGC permet de présenter de manière standardisée les données issues de capteurs de terrain. Certains logiciels comme 52North et istSOS permettent de gérer les donnéees de capteurs dans une BD internet et  de fournir les donneés de capteurs de manière standardisée via le protocole SOS. 
Ces protocoles standards de l'OGC  ont été présentés lors du Séminaire du réseau  SIST2015 à l'OSU Pytheas de Marseille <https://sist15.sciencesconf.org/program>

Traiter les données environnementales revient fréquemment à savoir les stocker et les gérer dans des BD relationnelles puis à les représenter sous forme de graphes 1D ou de cartes 2D
- Lorsque les valeurs sont acquises en 1 point en continue, on représente leur évolution en fonction du temps, on parle alors de "séries temporelles" (timeseries)
- Lorsque les valeurs sont acquises en 1 point le long d'un axe vertical profondeur ou altitude, on représente leur évolution en fonction du temps, on parle alors de "profils verticaux" (profiles)


   * Présentation du logiciel *istSOS*
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
       * Massimiliano Canata 

   * Collecte de mesures météorologiques à l'aide d'un système autonome : exemple de la métropole rennaise (Zone Atelier Armorique)           
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
           * Alban Thomas, Littoral, Environnement, Télédétection, Géomatique                                                                                                                                                                                                                                 

   * Distribution et visualisation de données avec Thredds, exemples d'utilisation au SEDOO
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
           * Guillaume Brissebrat, Service de données de l'OMP                                                                                                                                                                                                                                

   * Base de données «Observation» à la Station Biologique de Roscoff : retours d'expérience. 
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)
           * Mark Hoebeke, Station biologique de Roscoff [Roscoff]                                                                                                                                                      

   * Outil web interactif de visualisation et validation de séries temporelles.
       * <https://sist15.sciencesconf.org/program> (mettre le lien exact vers le fichier)Olivier LOBRY, Observatoire de REcherche Méditerranéen de l'Environnement    


## Développer les procédures d'intégration des données dans les bases de données                       

*  Intégrer les données dans sa base métier (MC. Quidoz) (<http://rbdd.cnrs.fr/IMG/pdf/integrer\_donnees.pdf?570/2006217c4509e4d59e6cbf44a291f997e7500153)>
*  UUID avec PostgreSQL : Pourquoi ? Comment ? (N. Raidelet) (<http://rbdd.cnrs.fr/IMG/pdf/uuid\_postgres.pdf?405/e6315023727441ee71c5d63415dd28285bc24952)>
*  Les + et les - de la solution ODK (MC. Quidoz \& PY. Arnould \& les stagiaires) (<http://rbdd.cnrs.fr/IMG/pdf/bilan\_odk.pdf?579/014d2664a47a1b155dde7a4ce7cf84db388194fa)>
*  Référence sur ODK (MC. Quidoz) (<http://rbdd.cnrs.fr/IMG/pdf/bibliographie.pdf?571/bbecc7bd883e4751efb6ccba6f99517ded5a6305)>
    
*  Outils nomades : validation des données (C. Plumejeaud) (<http://rbdd.cnrs.fr/IMG/pdf/anf\_rbbd\_2019\_outils\_mobiles\_tp\_qualite.pdf?573/e1425561fd10c6bd1dd92fdee22871bc427f9873)>
*  Retour terrain : la délicate question de l’intégration des données (PY. Arnould) (<http://rbdd.cnrs.fr/IMG/pdf/anf2019\_seshat.pdf?576/575888582b8771a01200c5a6a5e751f0964e0c33)>



