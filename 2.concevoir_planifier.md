# Concevoir et planifier

Concevoir et planifier est la seconde étape du cycle de vie de la donnée telle que définie dans la Cartographie des actions des réseaux métiers autour	de	la	gestion des données.	

A cette étape, il s'agir de définir les taches à accomplir pour réaliser le projet de recherche, d'élaborer un planning,	de rechercher d'éventuels partenaires et financements,d'élaborer les spécifications nécessaires, de définir les métadonnées qui seront utiles, de penser au futur plan	de	diffusion et bien d'autres actions de préparation et planification.	
	
Pour ces travaux de conception et de planification, les	réseaux	apportent un appui	sur la	gestion	de	projet,	les méthodologies	de	conduite	de	projet qui permettent par exemple la définition	des indicateurs utiles au projet, les outils pour assurer l'interopérabilité des systèmes mis en oeuvre. Ils fournissent des  recommandations et des retours d'expérience pour	la	rédaction des plans	de	gestion	de	données,	pour la définition du type	de	données	à	collecter,l'identification	de	nouveaux	supports	de	publication...

A ce stade, il	est aussi nécessaire	de	prévoir	le	mode de	collecte	et	de	stockage	afin d’organiser	la	traçabilité	en	amont, traçabilité qui permettra de	garantir	la	réutilisation	des données.	
	

## Contexte 

A cette étape, on aura déjà identifié les grands objectifs du projets et on se sera éventuellement appuyé sur la partie "Imaginer" de ce document.


## Evaluer les besoins 

Il est donc temps, par rapport au déroulement du projet, d'évaluer les différents besoins.

### Anticiper les interfaçages nécessaires (avec les utilisateurs ou entre bases de données),
  
Il convient de prendre en compte les besoins en lien avec les utilisateurs du projet, quelquefois appelés "use case", et ceux entre les différents sytèmes qui seront sollicités qu'ils exitent déjà ou qu'ils soient élaborés pour le projet.

A l'occasion de l'ANF "Système d’information embarqué, cahier/carnet de terrain et de laboratoire électronique : quelles interactions avec les bases de données ?" organisée en mai 2016, Nadine Mandran, du laboratoire LIG, explique comme intégrer l'utilisateur au sein d'un projet. Elle présente en parallèle, méthode Agile et Démarche centrée utilisateur. Le contenu de cette présentation est très concret et illustré par des exemples. 
* [Méthodes pour intégrer l’utilisateur dans la construction des applications](http://rbdd.cnrs.fr/IMG/pdf/utilisateurs\_anfrbdd.pdf?171/5b534aea6e9bfe597fcf71ff840c5cf48c67033c)      
    Nadine MANDRAN, 2016. 

## Mettre en place une gestion de projet

  Les aspects de conception et de planification nécessitent de mettre en place une méthodologie de gestion de projet. En complément, une analyse des risques et une analyse SWOT pourront également être menées.

   De façon à mieux comprendre l'amplitude de la gestion de projet et sa nécessaire adéquation avec la thématique scientifique du laboratoire et les contraintes qui lui sont afférentes, on pourra consulter la présentation de Myriam Ferro réalisée en 2017. Elle présente la démarche qualité mise en place au laboratoire "Etude de la dynamique des protéomes" ainsi que les outils déployés pour appuyer la démarche. 
   * [Gestion de projet dans le domaine de la recherche en biologie avec la mise en place d'outils tels que la mise en place d'une procédure R&D, de fiche projet, l'utilisation d'un LIMS et les gestion des anomalies](https://qer-2017.sciencesconf.org/data/program/2017_ANF_tracabilite_ferro.pdf)      
    Myriam Ferro, 2017


Dans d'autres domaines, on pourra s'inspirer de la "Méthode de conduite de la recherche en informatique centrée humain". Il s’agit des domaines de la recherche en informatique qui intègrent des utilisateurs pour construire de la connaissance scientifique et des outils supports à cette recherche. A titre d’exemple, nous pouvons citer les domaines concernés comme le domaine des Systèmes d’Information (SI), de l’Ingénierie des Interfaces Homme-Machine (IIHM) ou celui des Environnements Informatiques pour l'Apprentissage Humain (EIAH). Dans ces travaux de recherche se pose le problème du processus de conduite de la recherche et de la traçabilité des résultats et de la qualité des données. Cette méthode offre des outils conceptuels et techniques pour garantir la traçabilité du processus de conduite de la recherche. Elle porte le nom de THEDRE pour « Traceable Human Experiment Design Research ».  
   * [THEDRE : Méthode de conduite de la recherche en informatique centrée humain](https://qer-2017.sciencesconf.org/data/program/2017_ANF_tracabilite_mandran.pdf)      
    Nadine Mandran, 2017

A l'échelle d'un organisme il est aussi possible de doter les équipes de méthodes et d'outils de gestion de la qualité. L'INRA a développé une nouvelle politique qualité et en appui à cette politique, un outil de diagnostic, EureQUA: une méthode pour manager tout type d’activité. Diane Briard, lors de l'ANF qualité 2019, présente cette politique et détaille le fonctionnement d'Eurequa.
   * [Outil de Diagnostic EureQUA: une méthode simple d’aide à la décision en appui au pilotage des activités de recherche et d’expérimentation](https://qualsimp.sciencesconf.org/data/program/3_Outil_de_Diagnostic_Diane_BRIARD.pdf)      
    Diane Briard, INRA, 2019


La gestion d'un projet inclut aussi l'assurance produit.
L’assurance produit est l’ensemble des dispositions et activités définies et mises en place pour garantir que le produit atteigne les objectifs définis dans le cadre d’un projet ou d’une mission et qu’il soit sûr, fiable et disponible. 
C’est avant tout une question de bon sens et d’organisation interne. L’assurance produit s’applique à tout type de projet de manière transverse sur toutes les thématiques techniques et interagit avec tous les acteurs du projet.
Ces activités couvrent : 
- la maîtrise des risques et la sûreté de fonctionnement ; 
- l’assurance qualité (en conception et fabrication, approvisionnement et gestion de la sous-traitance, gestion des équipements, traçabilité) ;
- la maîtrise de la qualification des matériaux, composants et procédés ;
- la maîtrise et le contrôle de la contamination particulaire, moléculaire... ;
- la gestion de la documentation et de la configuration ;
- l’assurance qualité Logiciel.

Le réseau Qualité en Recherche a élaboré une [guide assurance produit](<http://qualite-en-recherche.cnrs.fr/IMG/pdf/Guide_Assurance_Produit-2019_05_24.pdf>) qui détaille ces points.

### Analyse de risques

L'analyse de risques et la gestion des risques sont des sujets importants de la gestion de projet. Un ensemble de présentations réalisées en décembre 2015 en dresse un panorama.

* [L’analyse des risques, leviers de différenciations des projets et d’amélioration de la qualité de la recherche](http://qualite-en-recherche.cnrs.fr/IMG/pdf/introduction_a_l_ecole_Risque.pdf)      
    Thierry Bontems, 2015
    
* [Le management des risques dans un projet](http://qualite-en-recherche.cnrs.fr/IMG/pdf/2015_12_03-ANF_QeR_Risques_projet_Lacombe-ppt.pdf)      
    Marielle LACOMBE, 2015

* [La cartographie des risques pour améliorer les services relatifs à la gestion des contrats et conventions](https://qualsimp.sciencesconf.org/data/program/17_La_cartographie_des_risques_pour_ame_liorer_les_services_relatifs_a_la_gestion_des_contrats_et_conventions_S._GOULIN_C._ROCH.pdf)      
    Catherine ROCH – Sabine GOULIN, 2015

* [Présentation de l'analyse SWOT : les usages et les conditions d'emploi de la méthode](https://qualsimp.sciencesconf.org/data/program/16_Outil_d_e_valuation_Analyse_SWOT_Sabine_GOULIN.pdf)      
    Sabine GOULIN, 2015

   

#### Définir le risque associé à un jeu de données 

Eric Quinton aborde la **question de la protection des données dans un contexte de menaces informatiques**. Que représente la donnée ?  Il précise qu’une donnée n’a pas de valeur intrinsèque, c’est la représentation d’une réalité, elle dépend de son contexte d’acquisition, de son traitement. Lorsque l’on travaille sur les données, on travaille toujours sur un processus d’acquisition dans le cadre d’un référentiel.
Certaines données doivent être protégées car elles comportent un risque si elles venaient à être diffusées et réutilisées. Face aux menaces informatiques qui n’ont jamais été aussi nombreuses (piratages, attaque, arnaques), il importe de **définir le risque et de comprendre comment l’intégrer à la gestion des données**. Il existe plusieurs définitions mais l’on s’accorde pour dire que c’est la conjonction entre une cible, un impact, une cause et une probabilité. Une fois la cible définie (un jeu de donnée) il convient de définir l’impact ou la gravité. Celui-ci s’évalue selon 3 **critères** (confidentialité de l’information, intégrité des données et disponibilité du système) classé chez IRSTEA selon un schéma détaillé correspondant à une échelle de 1 à 4. Il est important aussi de calculer l’impact en cas de défaillance – Pour chaque critère, on note 4 niveaux d’impact  estimés selon 4 thématiques. L’étude débouche sur un tableau récapitulatif qui est reporté dans le DMP. Ce t**ableau permet de définir l’impact** maximal et la sensibilité du système.
On ne peut connaitre toutes les menaces et les causes à prendre en compte. L’usage est de **consulter les recueils de bonnes pratiques et de se référer aux listes et référentiels existants**. La probabilité d’occurrence d’une menace est à évaluer en fonction du risque associé – On note 3 niveaux de risque : opportuniste, ciblé attaque concertée. 
En conclusion, Eric Quinton explique **comment intégrer concrètement le risque dans le plan de gestion des données en présentant des exercices pratiques**.


* Participer à l'organisation du management des données de la recherche : gestion de contenu et documentation des données 
    Eric Quinton, IRSTEA, 2016

* Vidéo 
   - <https://youtu.be/vuUEv0MbYrM>
   - <https://youtu.be/sHReS--G4Mg>
   - <https://youtu.be/u9P5ODxeLmE>
* Diapositives
   - <https://anfdonnees2016.sciencesconf.org/conference/anfdonnees2016/pages/dmp_analyse_securite.pdf>

### Sauvegarder les données

A ce stade il est important de prévoir une sauvegarde pour les données qui vont être collectées, crées, construites dans le cadre du projet. L'objet de ce paragraphe n'est pas de discuter le choix d'une technologie ou d'une stratégie mais simplement de rappeler de ne pas oublier de prévoir une sauvegarde.

## Amorcer un Plan de gestion de données 

Un Plan de Gestion de Données (PGD) ou Data Management Plan (DMP) est un document formalisé - un livrable du projet pour la plupart des appels à projets actuellement - explicitant la manière dont seront obtenues, documentées, analysées, disséminées et utilisées les données produites au cours et à l’issue d’un processus ou d’un projet de recherche.

L'initilisation du PGD dans cette phase est un préalable à sa mise a jour dans les étapes suivantes. Le PGD doit suivre les évolutions du projet.

### Comment créer un plan de gestion des données (DMP) ? 

Cette présentation présente dans une première partie le plan de gestion de données en perspective du cycle de vie des données et détaille les principe FAIR. Une seconde partie présente différents modèles de plans issus de plusieurs origines (INRA, appels à projets). C'est une excellente entrée en matière pour comprendre rapidement ce qu'est concrètement un plan de gestion de données.

   * [Plan de gestion des données.](http://rbdd.cnrs.fr/IMG/pdf/tempo-pgd.pdf?580/01010276848206d6f57d0d6c5d8d93a441f83668)   
    Marie-Claude QUIDOZ, 2019

Cette présentation de Marie Puren a été conçue pour animer un atelier de formation qui avait pour objectif de **définir un plan de gestion de donnée, identifier les 
éléments clés qui le constituent** et le créer. Cette présentation contient tout d’abord des éléments propres à **définir les données de la recherche, le modèle 
d’ouverture dans lequel elles s’inscrivent**, les **initiatives européennes et nationales qui les soutiennent**. Elle focalise ensuite sur la pratique de la gestion 
à proprement dite des données et ses implications (gérer, stocker, déposer) mais surtout définit,  décrit le **contenu formel du Plan de Gestion de données et  
les différentes étapes de gestion**.  Elle présente concrètement la **structuration du DMP** (**description des données, standards et métadonnées, partage et archivage 
es données)**, elle aborde les **questions juridiques** et  les **bonnes pratiques de gestion** notamment le **FAIR DATA**.

* [Participer à l'organisation du management des données de la recherche : gestion de contenu et documentation des données](https://anfdonnees2017.sciencesconf.org/data/pages/20170706_dmp_puren.pdf)   
    Marie Puren,  INRIA, 2017

Comme l'ont introduit les présentations précédentes, un plan de gestion de données ne se rédige pas seul dans son coin mais au contraire en associant les différents acteurs du projet. Il s'agit donc de rédiger collaborativement le PGD. La plateforme DMP OPIDOR de l'INIST fournit un service en réponse à ce besoin. Après un rappel du contexte autour de la gestion des données, cette présentation montre avec de nombreuses copies d'écran comment utiliser DMP OPIDoR, la plateforme proposée par l'INIST-CNRS à l'ensemble de la communauté enseignement supérieur recherche en France pour rédiger de façon collaborative un PGD. A ne pas manquer si vous souhaitez un panorama du contexte et si vous souhaitez savoir comment réaliser en pratique un plan de gestion de données

   * [Data management plan ? Plan de gestion de données ? DMP OPIDoR vous guide !](https://sist18.sciencesconf.org/data/pages/15_MC_Jacquemot_Perbal_L_Rassinoux_OPIDoR.pdf)   
    Laurent RASSINOUX, Marie-Christine JACQUEMOT-PERBAL, Institut de l’information scientifique et technique, 2018

### Le cas des logiciels

Les logiciels sont aussi des données, un peu particulières et qui méritent donc un modèle approprié de plan de gestion : le plan de gestion de logiciel. Le projet PRESOFT propose un modèle adapté à la fois au logiciel et au contexte de la recherche en France. Après une présentation du contexte, du modèle et de la procédure associée, les apports de PRESOFT sont détaillés.

   * [Plans de gestion de logiciels](https://jcad2019.sciencesconf.org/data/PRESOFT\_JCAD2019.pdf)   
    Geneviève Romier, Vincent Breton, CNRS-IN2P3, 2019 

### Retour d'expérience

Afin de conclure ce tour d'horizon des plans de gestion de données, ce retour d'expérience relatif au domaine de la biodiversité vous permettra de mieux comprendre comment utiliser les plans de gestion de données comme un véritable outil de gestion qui va bien au-delà du document administratif nécessaire à la validation du projet.

* [Du Plan de Gestion des Données au Datapaper : suivi des données scientifiques tout au long de leur cycle de vie.](https://sist18.sciencesconf.org/data/pages/16_W_Heintz_Du_plan_de_gestion_des_donnees_au_data_paper.pdf)   
    HEINTZ, Wilfried, 2018. 


## Vérifier les disponibilités des infrastructures (lieu, fournisseur du service, fonctionnalités, capacités et services)
GR : différencier pres générique (ici)
retour d'expérience sur ces infras (à déplacer vers traiter analyser)
Dans cette phase de montage de projet, il convient de choisir et de mettre en place des outils de gestion de projets tels que : 
    des listes fournies par un service de listes de discussions,
    des outils de partage de documents et de données dans des dossiers partagés en réseau ou de type "service de cloud",
    une plate forme de gestion de projet de type "redmine" ou autre,

Pour cela il est utile de connaitre les possibilités et ressources internes à l'unité et celles fournies par l'institution ou des partenaires extérieurs : Université, CNRS, Renater, etc...


### Infrastructures de traitement de données, calcul, stockage

   * Infrastructure pour l'open science EOSC
       * <https://jcad2019.sciencesconf.org/data/EOSC\_FranceGrilles\_Beckmann\_20191011.pdf>
   * Infrastructure de grille et de cloud EGI et France Grilles
       * Sur EGI : <https://jcad2019.sciencesconf.org/data/EGI\_update\_about\_services\_2019\_10\_10\_JCAD\_v3\_vf.pdf>
       * Sur le service de stockage de France Grilles : <https://jcad2019.sciencesconf.org/data/Poster\_FG\_iRODS\_2019\_JCAD.pdf>
       * Sur le cloud France Grilles :  <https://jcad2019.sciencesconf.org/data/posterJCAD2019\_Hamrouni\_vf.pdf>
GR : c'est un retour d'expérience. 


   * Infrastructures pour les bases de données
       * ANF « PostgreSQL Administration, premier niveau », novembre 2019
           * <http://rbdd.cnrs.fr/spip.php?article330>
       * ANF « PostgreSQL Performance », 2019
           * <http://rbdd.cnrs.fr/spip.php?article321>

   * Infrastructures pour les logiciels

   * Prévoir les modes de collecte et de stockage 

### les bases de données

   * Chaîne opératoire de réalisation d’une base de données. Isabelle BALY et Philippe GRISON, 2014. 
        * http://rbdd.cnrs.fr/IMG/pdf/anfcairn-rbdd_5et6juin2014_peti.pdf?190/e455c772dd0f972d6b785fc9662cd8bfe8555d6d

   Dans cette présentation réalisée lors de l'ANF CAIRN - rBDD "Comment concevoir une base de données en archéométrie ?", en juin 2014, Isabelle BALY et Philippe GRISON présentent les différentes étapes nécessaires à la conception et à la réalisation d'une base de données en archéométrie. Ils en détaillent les différentes phases : analyse ou d’audit, modélisation & développement de la base, migration des données et déploiement & développement d’un SGBD.
   
### Infrastructures pour l'information scientifique et technique

**Positionnement et offre globale de l’INIST dans le contexte IST en évolution **
* Claire François, (INIST
* Fredocs 2018 - Démarches innovantes en IST : expérimenter, proposer, (se) réinventer 3-5 octobre 2018, Albi
* pdf - https://fredoc2018.sciencesconf.org/data/pages/INIST_C_Francois.pdf

L’Institut de l’Information Scientifique et Technique, unité de service du CNRS déploie ses activités vers un projet d’ingénierie des connaissances qui s’articule 
autour de 3 axes principaux : **« Analyse et fouille de l’information », « Valorisation des données de la recherche », « Accès à l’information scientifique »**. Claire 
François présente ici un **panorama des outils et services proposés aux chercheurs** : portail d’accès aux ressources électronique (bibCNRS), plateforme d’accès aux 
archives scientifiques (ISTEX), une suite logicielle de mesure des usages des ressources éléctroniques (EzPAARSE.EzMESURE) pour faciliter l’accès à l’information 
scientifique aux chercheurs. Elle présente également les outils de formation à distance et services d’accompagnement tels que Doranum, Conditor, CoRea pour optimiser 
le partage et l’intéropérabilité des données de la recherche. Et Pour finir les outils d’analyse et fouille de l’information scientifique tels que LOTERRE, ISTEX, 
LODEX ou VISA TM pour créer et gérer la terminologie scientifique et permettre le recueil des données sur les publications et la production d’indicateurs 
bibliométriques

### Infrastructures thématiques

**« Réseau Quetelet : Banques de données pour les sciences sociales »**
* Roxane Silberman,  TGIR PROGEDO/Réseau Quetelet
* Frédocs2013 - Gestion et valorisation des données de la recherche -  7 au 10 octobre 2013, Aussois
* http://renatis.cnrs.fr/IMG/pdf/SILBERMAN_08102013.pdf 

Dans cette présentation très complète bien qu’ancienne, Roxane Silberman fait une **description  du Réseau Quetelet**, composante de la TGIR Progedo qui est une 
banque française de données pour les sciences sociales. Elle indique la spécificité des données collectées au sein de ce réseau qui peuvent être des **données 
individuelles, qualitatives**, parfois de santé publique et les **enjeux de protection de la vie privée**  associés à ces données. Elle retrace l’historique des premières 
banques de données pour lesquelles se posaient déjà  la **question de l’accès et du partage des données à caractère individuel**. Ce réseau s’inscrit dans une 
infrastructure européenne, le CESSDA (réseau européen des archives de données) et fournit des métadonnées accessibles à tous et en particulier aux chercheurs. 
Après avoir expliqué les grandes fonctions de Quetelet (dépôt, archivage, documentation, diffusion des données), elle revient sur quelques **enjeux pour l’état, 
les politiques publiques et autres  acteurs économiques**, le paysage qui se dessine autour de la donnée et qui bouscule les frontières dans le contexte de l’open data. 


 

      *
 
