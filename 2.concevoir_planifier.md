# Concevoir et planifier

Concevoir et planifier est la seconde étape du cycle de vie de la donnée telle que définie dans la Cartographie des actions des réseaux métiers autour	de	la	gestion des données.	

A cette étape, il s'agir de définir les taches à accomplir pour réaliser le projet de recherche, d'élaborer un planning,	de rechercher d'éventuels partenaires et financements,d'élaborer les spécifications nécessaires, de définir les métadonnées qui seront utiles, de penser au futur plan	de	diffusion et bien d'autres actions de préparation et planification.	
	
Pour ces travaux de conception et de planification, les	réseaux	apportent un appui	sur la	gestion	de	projet,	les méthodologies	de	conduite	de	projet qui permettent par exemple la définition	des indicateurs utiles au projet, les outils pour assurer l'interopérabilité des systèmes mis en oeuvre. Ils fournissent des  recommandations et des retours d'expérience pour	la	rédaction des plans	de	gestion	de	données,	pour la définition du type	de	données	à	collecter,l'identification	de	nouveaux	supports	de	publication...

A ce stade, il	est aussi nécessaire	de	prévoir	le	mode de	collecte	et	de	stockage	afin d’organiser	la	traçabilité	en	amont, traçabilité qui permettra de	garantir	la	réutilisation	des données.	
	

## Contexte 

A cette étape, on aura déjà identifié les grands objectifs du projets et on se sera éventuellement appuyé sur la partie "Imaginer" de ce document.


## Evaluer les besoins 

Il est donc temps, par rapport au déroulement du projet, d'évaluer les différents besoins.

### Anticiper les interfaçages nécessaires (avec les utilisateurs ou entre bases de données),
  
Il convient de prendre en compte les besoins en lien avec les utilisateurs du projet, quelquefois appelés "use case", et ceux entre les différents sytèmes qui seront sollicités qu'ils exitent déjà ou qu'ils soient élaborés pour le projet.

A l'occasion de l'ANF "Système d’information embarqué, cahier/carnet de terrain et de laboratoire électronique : quelles interactions avec les bases de données ?" organisée en mai 2016, Nadine Mandran, du laboratoire LIG, explique comme intégrer l'utilisateur au sein d'un projet. Elle présente en parallèle, méthode Agile et Démarche centrée utilisateur. Le contenu de cette présentation est très concret et illustré par des exemples.

* [Méthodes pour intégrer l’utilisateur dans la construction des applications](http://rbdd.cnrs.fr/IMG/pdf/utilisateurs\_anfrbdd.pdf?171/5b534aea6e9bfe597fcf71ff840c5cf48c67033c)  
    [vidéo](https://webcast.in2p3.fr/video/methodes_pour_integrer_l_utilisateur_dans_la_construction_des_applications)  
    Nadine MANDRAN, 2016  
Séminaire « Système d’information embarqué, cahier/carnet de terrain et de laboratoire électronique : quelles interactions avec les bases de données ? » (5 octobre 2016)

## Mettre en place une gestion de projet

  Les aspects de conception et de planification nécessitent de mettre en place une méthodologie de gestion de projet. En complément, une analyse des risques et une analyse SWOT pourront également être menées.

   De façon à mieux comprendre l'amplitude de la gestion de projet et sa nécessaire adéquation avec la thématique scientifique du laboratoire et les contraintes qui lui sont afférentes, on pourra consulter la présentation de Myriam Ferro réalisée en 2017. Elle présente la démarche qualité mise en place au laboratoire "Etude de la dynamique des protéomes" ainsi que les outils déployés pour appuyer la démarche.

   * [Gestion de projet dans le domaine de la recherche en biologie avec la mise en place d'outils tels que la mise en place d'une procédure R&D, de fiche projet, l'utilisation d'un LIMS et les gestion des anomalies](https://qer-2017.sciencesconf.org/data/program/2017_ANF_tracabilite_ferro.pdf)  
    Myriam Ferro, 2017  

Dans d'autres domaines, on pourra s'inspirer de la "Méthode de conduite de la recherche en informatique centrée humain". Il s’agit des domaines de la recherche en informatique qui intègrent des utilisateurs pour construire de la connaissance scientifique et des outils supports à cette recherche. A titre d’exemple, nous pouvons citer les domaines concernés comme le domaine des Systèmes d’Information (SI), de l’Ingénierie des Interfaces Homme-Machine (IIHM) ou celui des Environnements Informatiques pour l'Apprentissage Humain (EIAH). Dans ces travaux de recherche se pose le problème du processus de conduite de la recherche et de la traçabilité des résultats et de la qualité des données. Cette méthode offre des outils conceptuels et techniques pour garantir la traçabilité du processus de conduite de la recherche. Elle porte le nom de THEDRE pour « Traceable Human Experiment Design Research ».  

   * [THEDRE : Méthode de conduite de la recherche en informatique centrée humain](https://qer-2017.sciencesconf.org/data/program/2017_ANF_tracabilite_mandran.pdf)      
    Nadine Mandran, 2017

A l'échelle d'un organisme il est aussi possible de doter les équipes de méthodes et d'outils de gestion de la qualité. L'INRA a développé une nouvelle politique qualité et en appui à cette politique, un outil de diagnostic, EureQUA: une méthode pour manager tout type d’activité. Diane Briard, lors de l'ANF qualité 2019, présente cette politique et détaille le fonctionnement d'Eurequa.

   * [Outil de Diagnostic EureQUA: une méthode simple d’aide à la décision en appui au pilotage des activités de recherche et d’expérimentation](https://qualsimp.sciencesconf.org/data/program/3_Outil_de_Diagnostic_Diane_BRIARD.pdf)      
    Diane Briard, INRA, 2019


La gestion d'un projet inclut aussi l'assurance produit.
L’assurance produit est l’ensemble des dispositions et activités définies et mises en place pour garantir que le produit atteigne les objectifs définis dans le cadre d’un projet ou d’une mission et qu’il soit sûr, fiable et disponible. 
C’est avant tout une question de bon sens et d’organisation interne. L’assurance produit s’applique à tout type de projet de manière transverse sur toutes les thématiques techniques et interagit avec tous les acteurs du projet.
Ces activités couvrent : 
- la maîtrise des risques et la sûreté de fonctionnement ; 
- l’assurance qualité (en conception et fabrication, approvisionnement et gestion de la sous-traitance, gestion des équipements, traçabilité) ;
- la maîtrise de la qualification des matériaux, composants et procédés ;
- la maîtrise et le contrôle de la contamination particulaire, moléculaire... ;
- la gestion de la documentation et de la configuration ;
- l’assurance qualité Logiciel.

Le réseau Qualité en Recherche a élaboré une [guide assurance produit](http://qualite-en-recherche.cnrs.fr/IMG/pdf/Guide_Assurance_Produit-2019_05_24.pdf) qui détaille ces points.

### Analyse de risques

L'analyse de risques et la gestion des risques sont des sujets importants de la gestion de projet. Un ensemble de présentations réalisées en décembre 2015 en dresse un panorama.

* [L’analyse des risques, leviers de différenciations des projets et d’amélioration de la qualité de la recherche](http://qualite-en-recherche.cnrs.fr/IMG/pdf/introduction_a_l_ecole_Risque.pdf)      
    Thierry Bontems, 2015
    
* [Le management des risques dans un projet](http://qualite-en-recherche.cnrs.fr/IMG/pdf/2015_12_03-ANF_QeR_Risques_projet_Lacombe-ppt.pdf)      
    Marielle LACOMBE, 2015

* [La cartographie des risques pour améliorer les services relatifs à la gestion des contrats et conventions](https://qualsimp.sciencesconf.org/data/program/17_La_cartographie_des_risques_pour_ame_liorer_les_services_relatifs_a_la_gestion_des_contrats_et_conventions_S._GOULIN_C._ROCH.pdf)      
    Catherine ROCH – Sabine GOULIN, 2015

* [Présentation de l'analyse SWOT : les usages et les conditions d'emploi de la méthode](https://qualsimp.sciencesconf.org/data/program/16_Outil_d_e_valuation_Analyse_SWOT_Sabine_GOULIN.pdf)      
    Sabine GOULIN, 2015

   

#### Définir le risque associé à un jeu de données 

Eric Quinton aborde la **question de la protection des données dans un contexte de menaces informatiques**. Que représente la donnée ?  Il précise qu’une donnée n’a pas de valeur intrinsèque, c’est la représentation d’une réalité, elle dépend de son contexte d’acquisition, de son traitement. Lorsque l’on travaille sur les données, on travaille toujours sur un processus d’acquisition dans le cadre d’un référentiel.
Certaines données doivent être protégées car elles comportent un risque si elles venaient à être diffusées et réutilisées. Face aux menaces informatiques qui n’ont jamais été aussi nombreuses (piratages, attaque, arnaques), il importe de **définir le risque et de comprendre comment l’intégrer à la gestion des données**. Il existe plusieurs définitions mais l’on s’accorde pour dire que c’est la conjonction entre une cible, un impact, une cause et une probabilité. Une fois la cible définie (un jeu de donnée) il convient de définir l’impact ou la gravité. Celui-ci s’évalue selon 3 **critères** (confidentialité de l’information, intégrité des données et disponibilité du système) classé chez IRSTEA selon un schéma détaillé correspondant à une échelle de 1 à 4. Il est important aussi de calculer l’impact en cas de défaillance – Pour chaque critère, on note 4 niveaux d’impact  estimés selon 4 thématiques. L’étude débouche sur un tableau récapitulatif qui est reporté dans le DMP. Ce t**ableau permet de définir l’impact** maximal et la sensibilité du système.
On ne peut connaitre toutes les menaces et les causes à prendre en compte. L’usage est de **consulter les recueils de bonnes pratiques et de se référer aux listes et référentiels existants**. La probabilité d’occurrence d’une menace est à évaluer en fonction du risque associé – On note 3 niveaux de risque : opportuniste, ciblé attaque concertée. 
En conclusion, Eric Quinton explique **comment intégrer concrètement le risque dans le plan de gestion des données en présentant des exercices pratiques**.


* Participer à l'organisation du management des données de la recherche : gestion de contenu et documentation des données 
    Eric Quinton, IRSTEA, 2016

[ML il faudrait donner qq phrases sur le contenu de ces videos]
* Vidéo 
   - <https://youtu.be/vuUEv0MbYrM>
   - <https://youtu.be/sHReS--G4Mg>
   - <https://youtu.be/u9P5ODxeLmE>
* Diapositives
   - <https://anfdonnees2016.sciencesconf.org/conference/anfdonnees2016/pages/dmp_analyse_securite.pdf>

### Sauvegarder les données
[ML : n'y a t'il pas des recommendation resinfo sur les sauvegardes?]

Une fois que les données sont acquises et stockées sur un environnement de travail, à ce stade il est important de prévoir une **sauvegarde** pour les données qui seront collectées, 
crées, construites dans le cadre du projet. 
L'objet de cette phase péparatoire n'est pas  de discuter le choix d'une technologie ou d'une stratégie mais simplement de se préoccuper de prévoir la sauvegarde des données, 
et se poser les bonnes questions :
- quel volume approximatif devrons-nous sauvegarder? 
- selon quelle périodicité : quotidienne? hebdomadaire? mensuelle?
- Les baies de stockages sont-elles disponibles? 
- sont-elles sous contrat de maintenance? y a t-il besoin d'une externalisation?
- les données devront-elles être accédées fféquemment ? en temps réeel?
- y a-t'il assez de place sur nos installations? 
- etc...



## Amorcer un plan de gestion de données 

Un Plan de Gestion de Données (PGD), ou Data Management Plan (DMP) en anglais, est un document formalisé - un livrable du projet pour la plupart des appels à projets actuellement - 
explicitant la manière dont seront obtenues, documentées, analysées, disséminées et utilisées les données produites au cours et à l’issue d’un processus ou d’un projet de recherche.

A noter qu'il existe des modèles de plans de gestion de données dits "de structure" dont la période considérée s'étend au-delà de la durée d'un seul projet. 
(voir si on a des références à indiquer)

L'initilisation du PGD dans cette phase est un préalable à sa mise a jour nécessaire dans les étapes suivantes. Le PGD doit suivre les évolutions du projet.

### Comment créer un plan de gestion des données (PGD) ? 

Cette présentation présente dans une première partie le plan de gestion de données en perspective du cycle de vie des données et détaille les principe FAIR. Une seconde partie présente différents modèles de plans issus de plusieurs origines (INRA, appels à projets). C'est une excellente entrée en matière pour comprendre rapidement ce qu'est concrètement un plan de gestion de données.

   * [Plan de gestion des données.](http://rbdd.cnrs.fr/IMG/pdf/tempo-pgd.pdf?580/01010276848206d6f57d0d6c5d8d93a441f83668)   
    Marie-Claude QUIDOZ, 2019

Cette présentation de Marie Puren a été conçue pour animer un atelier de formation qui avait pour objectif de **définir un plan de gestion de donnée, identifier les 
éléments clés qui le constituent** et le créer. Cette présentation contient tout d’abord des éléments propres à **définir les données de la recherche, le modèle 
d’ouverture dans lequel elles s’inscrivent**, les **initiatives européennes et nationales qui les soutiennent**. Elle focalise ensuite sur la pratique de la gestion 
à proprement dite des données et ses implications (gérer, stocker, déposer) mais surtout définit,  décrit le **contenu formel du Plan de Gestion de données et  
les différentes étapes de gestion**.  Elle présente concrètement la **structuration du DMP** (**description des données, standards et métadonnées, partage et archivage 
es données)**, elle aborde les **questions juridiques** et  les **bonnes pratiques de gestion** notamment le **FAIR DATA**.

* [Participer à l'organisation du management des données de la recherche : gestion de contenu et documentation des données](https://anfdonnees2017.sciencesconf.org/data/pages/20170706_dmp_puren.pdf)   
    Marie Puren,  INRIA, 2017

Comme l'ont introduit les présentations précédentes, un plan de gestion de données ne se rédige pas seul, mais au contraire en associant les différents acteurs du projet. 
Il s'agit donc de rédiger collaborativement le PGD. La plateforme "DMP OPIDoR" de l'INIST fournit un service en réponse à ce besoin à l'ensemble de la communauté enseignement supérieur 
recherche en France pour rédiger de façon collaborative un PGD. Après un rappel du contexte autour de la gestion des données, cette présentation montre avec de nombreuses copies d'écran 
comment utiliser "DMP OPIDoR". A ne pas manquer si vous souhaitez un panorama du contexte et si vous souhaitez savoir comment réaliser en pratique un plan de gestion de données en collaborant 
avec vos collègues.

   * [Data management plan ? Plan de gestion de données ? DMP OPIDoR vous guide !](https://sist18.sciencesconf.org/data/pages/15_MC_Jacquemot_Perbal_L_Rassinoux_OPIDoR.pdf)   
    Laurent RASSINOUX, Marie-Christine JACQUEMOT-PERBAL, Institut de l’information scientifique et technique, 2018

Des discussions autour d'une Table ronde " Les Plans de Gestion des Données des projets Scientifiques, quels impacts pour les centres de Calcul et de Données ?" 
vous permettraont aussi d'en voir les implications pour les centres de  calcul et de données.

* [Vidéo de la table ronde](https://jcad2019.sciencesconf.org/data/TR_JCAD2019_V3.pdf)


### Le cas des logiciels

Les logiciels sont aussi des données, un peu particulières et qui méritent donc un modèle approprié de plan de gestion : le plan de gestion de logiciel. 
Le projet PRESOFT propose un modèle adapté à la fois au logiciel et au contexte de la recherche en France. Après une présentation du contexte, du modèle et de la procédure associée, 
les apports de PRESOFT sont détaillés. A noter que le modèle proposé par PRESOFT s’étend sur l'ensemble de la "vie" du logiciel depuis l'idée avec les documents préparatoires jusqu'à la 
préservation (sous toutes ses formes) et qu'il prend en compte toutes les formes de financement (projets, stages...)

   * [Plans de gestion de logiciels](https://jcad2019.sciencesconf.org/data/PRESOFT\_JCAD2019.pdf)   
    Geneviève Romier, Vincent Breton, CNRS-IN2P3, 2019 

### Retour d'expérience

Afin de conclure ce tour d'horizon des plans de gestion de données, ce retour d'expérience relatif au domaine de la biodiversité vous permettra de mieux comprendre comment utiliser les plans de gestion de données comme un véritable outil de gestion qui va bien au-delà du document administratif nécessaire à la validation du projet.

* [Du Plan de Gestion des Données au Datapaper : suivi des données scientifiques tout au long de leur cycle de vie.](https://sist18.sciencesconf.org/data/pages/16_W_Heintz_Du_plan_de_gestion_des_donnees_au_data_paper.pdf)   
    HEINTZ, Wilfried, 2018. 


## Vérifier les disponibilités des infrastructures (lieu, fournisseur du service, fonctionnalités, capacités et services)
proposition GR : Identifier les infrastructures qui répondent aux besoins du projet et choisir celles qui correspondent aux critères du projet.

GR : différencier pres générique (ici)
retour d'expérience sur ces infras (à déplacer vers traiter analyser)

Une fois les besoins exprimés, il faut identifier les infrastructures nécessaires à la réalisation du projet. On apportera également un soin particulier aux différents critères de choix de ces infrastructures.

[CAT OPIDoR](https://cat.opidor.fr/index.php/Cat_OPIDoR,_wiki_des_services_d%C3%A9di%C3%A9s_aux_donn%C3%A9es_de_la_recherche) recense les services dédiés aux données de la recherche en perspective du cycle de vie des données et par type de service. Ce catalogue se présente sous la forme d'un wiki, n'hésitez donc pas à le compléter si besoin. 

Les présentations détaillées de différentes infrastructures et de leurs services citées ci-dessous peuvent vous permettre à la fois de découvrir le large paysage de l'offre en Europe et en France mais aussi de vérifier rapidement si les critères de votre projet peuvent être remplis par les différentes infrastructures et leurs offres de services.

### Infrastructures de travail collaboratif

Dans cette phase de montage de projet, il convient de choisir et de mettre en place des outils de gestion de projets tels que : 
- des listes de discussion fournies par un service de gestion de listes,
- des outils de partage de documents et de données dans des dossiers partagés en réseau ou de type "service de cloud",
- une plate forme de gestion de projet de type "redmine" ou autre,

Pour cela il est utile de connaitre les possibilités et ressources internes à l'unité et celles fournies par l'institution ou des partenaires extérieurs : Université, CNRS, Renater, etc...


### Infrastructures de traitement de données, calcul, stockage

De nombreuses infrastructures offrent des services à la communquté scientifique. Il convient de choisir celle(s) qui conviennent le mieux pour chaque projet.

**Infrastructure Européenne pour l'open science : EOSC (en cours de montage)**

   Cette présentation réalisée par Volker Beckmann, chargé de mission CNRS-EOSC fait le point sur les principales questions que vous vous posez peut-être sur EOSC : Qu'est ce que EOSC ?	Où en est-on et quelles sont les prochiane étapes ? Comment puis-je contribuer et/ ou bénéficier ? EOSC en France. France	Grilles: un pilier de l'infrastructure calcul en France	et un noyau possible pour le French	Open Science Cloud.

* [EOSC et France Grilles: prochaines étapes](https://jcad2019.sciencesconf.org/data/EOSC_FranceGrilles_Beckmann_20191011.pdf)   
    Volker Beckmann, CNRS-IN2P3, 2019

**Infrastructure Européenne EGI (différents services basés sur des infrastructures grille et cloud), egi.eu**

L'infrastructure EGI a été présentée de façon complète en 2018 lors des JCAD, Journées Calcul et Données : la fédération, les participants, le catalogue de services, les utilisateurs, le positionnement dans EOSC. Le projet EOSC-Hub qui participe à la construction d'EOSC est également détaillé. C'est la présentation à consulter si vous souhaitez savoir ce qu'est EGI.

* [EGI, the EOSC and the Hub](https://jcad2018.sciencesconf.org/data/20181024_JCAD_EGI_v1.1.pdf)  
    [vidéo EGI, the EOSC and the Hub](https://webcast.in2p3.fr/video/egi)   
    Yannick Legré, directeur de la fondation EGI, 2018

Une présentation des évolutions a eu lieu en 2019 avec un focus sur quelques services EGI - Check-in, Cloud, Stockage, Notebooks, Application on Demand - et quelques communautés utilisatrices.

* [Update about EGI and services to support user communities and Federation's participants](https://jcad2019.sciencesconf.org/data/EGI_update_about_services_2019_10_10_JCAD_v3_vf.pdf)      
    [vidéo](https://prismes.univ-toulouse.fr/player.php?code=4Q88P63z&width=100%&height=100%)   
    Baptiste Grenier, fondation EGI, 2019


**Infrastructure France Grilles, www.france-grilles.fr**

Le catalogue de services de France Grilles propose des services de traitement de données qui s'appuient sur une infrastructure de cloud et une infrastructure cloud ainsi que des services de stockage de données. L'ensemble est interconnecté permettant aux données stockées d'être traitées grâce aux services grille et cloud.

* Un poster présente le service de stockage de France Grilles : [FG-iRODS : un service de gestion de données pour les communautés scientifiques à l'échelle nationale et européenne basé une infrastructure fédérée](https://jcad2019.sciencesconf.org/data/Poster_FG_iRODS_2019_JCAD.pdf)   
    Emmanuel Medernach, Jérôme Pansanel, Raphaël Flores, Christine Gondrand, Patrick Moreau, Vincent Negre, Genevieve Romier, 2019

* Un autre poster a pour objet le cloud France Grilles :  [FG-Cloud: the French Academic Cloud for Scientific computing](https://jcad2018.sciencesconf.org/data/Poster_FG_Cloud_2018.pdf)   
    Groupe FG-Cloud, 2018

Il est aussi important de se faire une idée à travers des retours d'expérience réalisés par des collègues. En voici quelques exemples récents :

Le projet Phénome, Infrastructure nationale de phénomique végétale, regroupe sur 9 sites des plateformes expérimentales de phénotypage haut-débit(champ, serre, omique). Un système complet a été mis en place pour ce projet, système qui s'appuie sur les services FG-iRODS et FG-Cloud.

* [Déploiement de la plateforme de traitement des données phénotypage haut débit 4P sur l'infrastructure France Grilles](https://jcad2019.sciencesconf.org/data/4P.pdf)   
    [vidéo](https://prismes.univ-toulouse.fr/player.php?code=P0420GlL&width=100%&height=100%)   
    Vincent Negre, Eric David, Philippe Burger, Romain Chapuis, Boris Adam,  Anne Tireau, Patrick Moreau, Antony Tong, Samuel Thomas, Gallian Colombeau, Pascal Neveu, Jérôme Pansanel, Frédéric Baret, Marie Weiss, 2019

**Centres de calcul de GENCI**

GENCI et ses trois centres nationaux fournissent des moyens de calcul de niveau Tier 1 pour les utilisateurs nationaux. Cette présentation fait le tour des différentes centres, de leurs équipements et des différentes initiatives pilotées par GENCI. 

* [Actualité GENCI](https://jcad2019.sciencesconf.org/data/Presentation_JCAD_GENCI.pdf)   
    [vidéo](https://prismes.univ-toulouse.fr/player.php?code=0j2Egs4s&width=100%&height=100%)   
    Philippe Lavocat représenté par Elise Quentel et Jean-Philippe Proux, GENCI, 2019

**Infrastructures des mésocentres et centres régionaux, quelques exemples**
 
[=> choisir des pres HPC]

Il est aussi possible d'utiliser des ressources forunies par plusieurs mésocentres dans le cadre d'un même projet. Ce retour d'expérience dans le domaine de la chimie en est un témoignage.

* [Calculs de chimie quantique distribués entre méso-centres avec Quantum Package](https://jcad2019.sciencesconf.org/data/JCAD2019AScemama.pdf)
    [vidéo](https://prismes.univ-toulouse.fr/player.php?code=6E3Cefg2&width=100%&height=100%)   
    Anthony Scemama, Patrick BOUSQUET-MELOU, Marie-Sophie Cabot, Nicolas Renon


**Infrastructure pour les expériences à grande échelle en informatique**

SILECS, Super Infrastructure for Large-scale Experimental Computer Science est une infrastructure dédiée aux expériences à grande échelle en informatique basée sur les infrastructures FIT et GRID'5000. Cette infrastructure, tout en conservant les objectifs de FIT et GRID'5000, vise de nouveaux challenges : IoT et Clouds, nouvelles generations de plateformes Cloud et de piles logicielles (Edge, FOG), applications de Data streaming, gestion de volumes de données importants, mobilité...

* [SILECS, une infrastructure pour les expériences à grande échelle en informatique](https://jcad2019.sciencesconf.org/data/silecs_jcad2019.pdf)   
    [vidéo](https://prismes.univ-toulouse.fr/player.php?code=4HxTGQp2&width=100%&height=100%)   
    Frédéric Desprez, Christian Perez, Inria, 2019

**Les "datalakes"**

De nouvelles infrastructures de stockage de grandes quantités de données apparaissent dans le paysage. Plusieurs présentations vous permettront de vous faire une idée sur ce qu'est un Data Lake même si le concept n'est pas encore complétement défini et figé.

Jean-Pierre Gleyze présente le contexte du CNES, quelques applications et leur dimensionnement. Les points de vue des utilisateurs et des administeurs des infrastructures sont exposés, aussi cet exposé intéressera autant les informaticiens que les utilisateurs scientifiques.  

*  [Keynote : Infrastructures de traitement de données : vers un datalake CNES](https://jcad2019.sciencesconf.org/data/JACD_2019_datalake_CNES.pdf)   
    [vidéo](https://prismes.univ-toulouse.fr/player.php?code=x9b2k0Gd&width=100%&height=100%)   
    Jean-Pierre Gleyze, CNES, 209

CEBA, a pour ambition la création d’un « grand » observatoire de l’environnement en Auvergne, unique en Europe. Ce cloud environnemental permettra la gestion des données à tous les stades de leur cycle de vie. Il propose différents services comme un site Web, des outils d’ingestion, un moteur d’indexation, un catalogue de données, des outils de visualisation qui s'appuyent sur une infrastructures incluant des bases de données et système de fichiers.

* [CEBA, un data lake dédié à l'observation des écosystèmes environnementaux](https://jcad2019.sciencesconf.org/data/20191002_JCAD_CEBA.pdf)   
    [vidéo](https://prismes.univ-toulouse.fr/player.php?code=gS95Z11G&width=100%&height=100%)   
    Francis Ogereau, Vincent Breton, Alexandre Claude, David Grimbichler, Antoine Mahul, Gilles Mailhot, Jérémy Mezhoud, Christine Plumejeaud, Laurent Royer,  Estelle Théveniaud, Richard Vandaele, David Sarramia, 2019

Le projet international DOMA n’est pas un projet de DATALAKE ni un produit mais une organisation qui participera à définir ce que sera un DATALAKE. Ses objectifs sont de
suivre les avancées et les développements, être un forum de partage d’informations et veiller à l’interopérabilité des différentes solutions de stockage. Une première présentation de DOMA a eu lieu en 2018 et une présentation des évolutions en 2019.

* [Projet DOMA : Réflexions et axes de recherche pour les services de stockage de données scientifiques à l'horizon 2025.](https://jcad2018.sciencesconf.org/data/DOMA_JCAD_v2.pdf)   
    [vidéo](https://webcast.in2p3.fr/video/projet-doma-reflexions-et-axes-de-recherche-pour-les-services-de-stockage-de-donnees-scientifiques-a-lhorizon-2025)   
    Eric Fede, Centre de Calcul de l'IN2P3, CNRS, 2018

* [Projet DOMA : Retour sur la première année des études faites autour des futurs services de stockage de données scientifiques.](https://jcad2019.sciencesconf.org/data/DOMA_JCAD_2019_v2.pdf)   
    [video](https://prismes.univ-toulouse.fr/player.php?code=8zxEkSuf&width=100%&height=100%)   
    Eric Fede, CC-IN2P3, CNRS, 2019


**Infrastructures pour les logiciels**



**Prévoir les modes de collecte et de stockage** 


**Prévoir d'utiliser un cahier de laboratoire**


### Les bases de données

La gestion des données dans des Bases de données relationnelles est un gage de structuration cohérente, et permet une interrogation des données
par des opérateurs du langage SQL (system query language)

Plusieurs Systèmes de Gestion de Bases de Donnée (SGBD) existent dans le monde du logiciel libre, cependant, Postgresql est le SGBD conseillé par la
[circulaire Ayrault](http://rbdd.cnrs.fr/IMG/pdf/mcq_jrbdd2017.pdf?381/0207fc9b42426c781066e710f0702bdbe8c90096) que Marie-Claude Quidoz a présentée en 2017.  

La maîtrise de Postgresql est donc importante et plusieurs formations complètes ont été organisées à ce sujet : 

* [ANF « PostgreSQL Administration, premier niveau »](http://rbdd.cnrs.fr/spip.php?article330), novembre 2019
* [ANF « PostgreSQL Performance »](http://rbdd.cnrs.fr/spip.php?article321), 2019


Bien aborder la mise en place est l'objectif de la présentation "Comment concevoir une base de données en archéométrie ?", réalisée en juin 2014 par Isabelle BALY et Philippe GRISON. Ils présentent les différentes étapes nécessaires à la conception et à la réalisation d'une base de données en archéométrie. Ils en détaillent les différentes phases : analyse ou d’audit, modélisation & développement de la base, migration des données et déploiement & développement d’un SGBD.

* [Chaîne opératoire de réalisation d’une base de données.](http://rbdd.cnrs.fr/IMG/pdf/anfcairn-rbdd_5et6juin2014_peti.pdf?190/e455c772dd0f972d6b785fc9662cd8bfe8555d6d)   
    Isabelle BALY et Philippe GRISON, 2014. 


  
   
### Infrastructures pour l'information scientifique et technique

L’Institut de l’Information Scientifique et Technique, unité de service du CNRS déploie ses activités vers un projet d’ingénierie des connaissances qui s’articule 
autour de 3 axes principaux : **« Analyse et fouille de l’information », « Valorisation des données de la recherche », « Accès à l’information scientifique »**. Claire 
François présente ici un **panorama des outils et services proposés aux chercheurs** : portail d’accès aux ressources électronique (bibCNRS), plateforme d’accès aux 
archives scientifiques (ISTEX), une suite logicielle de mesure des usages des ressources éléctroniques (EzPAARSE.EzMESURE) pour faciliter l’accès à l’information 
scientifique aux chercheurs. Elle présente également les outils de formation à distance et services d’accompagnement tels que Doranum, Conditor, CoRea pour optimiser 
le partage et l’intéropérabilité des données de la recherche. Et Pour finir les outils d’analyse et fouille de l’information scientifique tels que LOTERRE, ISTEX, 
LODEX ou VISA TM pour créer et gérer la terminologie scientifique et permettre le recueil des données sur les publications et la production d’indicateurs 
bibliométriques

* [Positionnement et offre globale de l’INIST dans le contexte IST en évolution](https://fredoc2018.sciencesconf.org/data/pages/INIST_C_Francois.pd)   
    Claire François, 208


### Infrastructures thématiques

Dans cette présentation très complète bien qu’ancienne, Roxane Silberman fait une **description  du Réseau Quetelet**, composante de la TGIR Progedo qui est une 
banque française de données pour les sciences sociales. Elle indique la spécificité des données collectées au sein de ce réseau qui peuvent être des **données 
individuelles, qualitatives**, parfois de santé publique et les **enjeux de protection de la vie privée**  associés à ces données. Elle retrace l’historique des premières 
banques de données pour lesquelles se posaient déjà  la **question de l’accès et du partage des données à caractère individuel**. Ce réseau s’inscrit dans une 
infrastructure européenne, le CESSDA (réseau européen des archives de données) et fournit des métadonnées accessibles à tous et en particulier aux chercheurs. 
Après avoir expliqué les grandes fonctions de Quetelet (dépôt, archivage, documentation, diffusion des données), elle revient sur quelques **enjeux pour l’état, 
les politiques publiques et autres  acteurs économiques**, le paysage qui se dessine autour de la donnée et qui bouscule les frontières dans le contexte de l’open data. 

* [Réseau Quetelet : Banques de données pour les sciences sociales](http://renatis.cnrs.fr/IMG/pdf/SILBERMAN_08102013.pdf)   
    Roxane Silberman, 2013
