# Publier et diffuser


Cette dernière étape d’un projet de  recherche représente un peu la finalité de toute une politique de gestion de données puisqu'elle vise à publier pour pouvoir diffuser et réutiliser des données de qualité selon des formats et des processus interopérables.

L’accompagnement  des  réseaux s’exerce sur la publication des données dans des entrepôts ou des plateformes techniques, pour en permettre l’accès, ainsi que sur la documentation des données avec des métadonnées descriptives, et leurs formats d’exploitation pour en assurer la réutilisabilité.

Ainsi les réseaux travaillent sur l’ensemble des informations (données, métadonnées, modes opératoires, échantillons, publications, visualisation et interfaces graphiques) nécessaires à la mise en œuvre des supports de diffusion et de valorisation les plus pertinents en rapport avec l’objectif du projet initial

Cette étape de publication et de diffusion est désormais souvent accompagnée d'une action d'*identification* des données via des identifiants pérennes, et de dépots dans des entrepots de données.


## Communiquer et documenter  

### Finaliser le PGD 

En fin de projet il est nécessaire de mettre à jour et finaliser la rédaction du plan de gestion de données. Vérifier que les premières informations qui ont été rédigée sont encore valides et valables, et mettre à jour en rajoutant les dernières informations nécessaires.
              
## Publier les métadonnées

- **Utilisation de catalogues de metadonnées**

Les *catalogues de metadonnées* représentent un moyen cohérent et rigoureux pour décrire et publier des jeux de données. 
Ils permettent de faciliter la recherche et l'identification des données (F de FAIR)

Pour être interopérables, ces catalogues s'appuient en général sur des normes pour représenter les métadonnées.
Par exemple, dans les sciences de  l'environnement la norme ISO 19115 et la norme ISO 19139 sont des références pour représenter les données géo-spatialisées et l'information géographique dans le domaine des métadonnées.

- L'ISO 19115-1 définit le schéma requis pour décrire des informations géographiques et des services au moyen de métadonnées. 
Elle fournit des informations concernant l'identification, l'étendue, la qualité, les aspects spatiaux et temporels, le contenu, la référence spatiale, la représentation des données, la distribution et d'autres propriétés des données géographiques numériques et des services.

- L'ISO 19139 définit le schéma d'implémentation XML pour représenter les métadonnées iso 19115

En ce sens, dans le domaine environnemental où les données proviennent fréquemment de mesures géolocalisées sur le terrain, le logiciel GeoNetwork [https://geonetwork-opensource.org/](https://geonetwork-opensource.org/ ) est un des logiciel de référence pour décrire et représenter les jeux de données géolocalisés, et constituer un *catalogue* qui inventorie les différents jeux de données d'un Institut.

Ce logiciel permet d’interagir avec d'autres catalogues de ressources spatialisées via le Web (Catalogue Services for the Web, dite CSW)et permet ainsi de construire un réseau de catalogues interagissant les uns avec les autres, réseau notamment demandé par la directive Européenne "Inspire".

Le logiciel GeoNetwork utilise en outre le protocole WMS (Web Map Service) de l'OGC, pour pouvoir interagir avec des logiciels cartographiques comme [GeoServer](http://geoserver.org/), ce qui permet de représenter les points de mesures sur une carte et de pouvoir accéder aux données brutes associées à un point de mesure Géolocalisé.

L'utilisation des logiciels GeoNetwork et GeoServer a été traitée par une action de formation du [réseau SIST](https://sist.cnrs.fr/). Pour lequel on trouvera les informations
* - [https://sist.cnrs.fr/les-formations/anf-2017-1](https://sist.cnrs.fr/les-formations/anf-2017-1)
* - [et les documentations associés sur les logiciels étudiés GeoNetwork et GeoServer ](https://sist.cnrs.fr/les-formations/supports-des-anf-gestion-de-donnees-dobservation/supports-des-anf-gestion-de-donnees-dobservation-les-outils-informatiques-pour-la-valorisation)


Dans cette présentation M. Treguer présente le catalogue Sextant [au journées SIST16](https://sist16.sciencesconf.org/resource/page/id/6)
* <https://sist16.sciencesconf.org/data/pages/03_M_Treguer.pdf> qui utilise GeoNetwork.


### Utilisation de thesaurus 

Pour être interopérables, les catalogues de métadonnées se doivent d'utiliser des vocabulaires contrôlés relevant de la discipline scientifique concernée. Les thésaurus sont des liste organisées de termes contrôlés et normalisés (descripteurs et
non descripteurs) représentant les concepts d'un domaine de la connaissance. Un thésaurus permet d'organiser et de structurer un vocabulaire contrôlé

De nombreux thesaurus existent comme celui de "Inspire" ou "GEMET" qui est un thésaurus documentaire multilingue développé et publié par l'Agence européenne pour l'environnement, cependant selon le domaine scientifique certains doivent être créés ou sont en perpétuelle évolution

Baptiste Laporte s'est penché sur la création d'un thésaurus collaboratif, et présente les besoins pour un thésaurus, le besoin d'outils simples, la dynamique de groupe pour la création de l'outil, le tout illustré par le groupe CESAB BETSI avec l'utilisation du thésauform et l'annotation des données dans leur base de données à partir du vocabulaire créé.

Dans cette présentation, MC Quidoz présente "Thesauform" :
un outil collaboratif pour faciliter la création de vocabulaire contrôlé par des experts de domaine
https://sist18.sciencesconf.org/data/pages/12_MC_Quidoz_Thesauform.pdf


* Création d'un thésaurus collaboratif : cas d'un groupe CESAB,  Baptiste Laporte (Centre de synthèse et d’analyse sur la biodiversité / Fondation pour la Recherche sur la Biodiversité), 2015
  * transparents de la présentation : <http://rbdd.cnrs.fr/IMG/pdf/creation_d_un_thesaurus_collaboratif.pdf?139/f6b1cdc1818726f3cdfc7646cc98afb22687cfd5>




## Utiliser des Identifiants pérennes

Afin d'être citées et réutilisées, les données doivent disposer d'un *identifiant perenne* pour qu'un jeu de données ("dataset") soit référencé de manière univoque, visible et accessible au même titre que les publications.  


### Le cas des documents :

Il existe différents types d'identifiants pérennes pour toutes sortes d'objets y compris les humains. Cet article de J-L Archimbaud fait le point sur les identifiants des documents numériques et leurs usages :

* [Identifiants des documents numériques : ISBN, ISSN, URL, Handle, DOI, OpenURL, OAI, ARK](http://rbdd.cnrs.fr/IMG/pdf/2015.10.ident-num.jla.v3.1.pdf?141/a989c95a6a9294128c99df8e2cfe4932718d2416)
Jean-Luc Archimbaud

Il faut aussi noter que dans le domaine de la bioinformatique, des identifiants uniques sont attribués aux enregistrements de séquences DNA ou de protéines. Ils sont nommés [accession number](https://en.wikipedia.org/wiki/Accession_number_(bioinformatics).

### Les DOI : "Digital Object Identification"

Les D.O.I (Digital Object Identification) garantissent un lien stable à la ressource en ligne. Ils font correspondre en permanence l’identité de la ressource à sa localisation sur le web. Ils permettent de citer les données de manière univoque et  que
l'on puisse les lier aux publications ou à tout autre produit de recherche. Ils concourent donc à l'identification, la traçabilité, et à l'interopérabilité des données.  

L'obtention de D.O.I se fait aupres de [l'organisme international "Datacite"](https://doi.datacite.org/) ou bien tout partenaire contractualisé avec Datacite. Il implique des devoirs de la part du déposant, qui est de maintenir un lien permanent vers les données identifiées pendant une certaine durée, à travers une page de description (appelée aussi "*landing page*") qui permet de fournir les métadonnées principales pour décrire les données et d'y accéder.

Pour créer une "landing page", page d'accueil pour décrire un jeu de données, il faut s'assurer que certaines métadonnées obligatoires sont bien mentionnées et renseignées pour permettre une recherche .
- Le site Datacite rappelle quelles sont les métadonnées obligatoires : https://support.datacite.org/docs/schema-mandatory-properties-v43

Pour en savoir plus sur les identifiants pérennes :
<https://doranum.fr/identifiants-perennes-pid/>;

Attention la pérennité est purement une question de service et n'est pas inhérente à un objet, ni conféré par une syntaxe de nommage particulier.  La pérennité du lien vers la localisation de la ressource est de la responsabilité du déposant ou du créateur de l'identifiant.

**Publier avec des identifiants pérennes**

[rajouter du texte sur ces presentation]

* Pour en savoir plus sur le DOI de DataCite :
<https://seminaire.inrae.fr/data/content/download/3449/36374/version/1/file/03+Yahia+doi+datacite.pdf>

* nécessité de publier en identifiant les jeux de données par des  "DOI": 
DOI de DataCite : un système d'identification pour valoriser vos données de la recherche
présentation :<https://sist16.sciencesconf.org/data/pages/15_M_Yahia.pdf>


* video : <https://nuage.osupytheas.fr/s/hxjuXQwST6oZwsH/download?path=%2F\&files=16-DOI-Yahia-Inist-SIST2016.mp4>
Mohamed Salah Yahia, Institut de l'information scientifique et technique du CNRS                                         

* "DataCite : identifiants pérennes pour le partage des données »
http://renatis.cnrs.fr/IMG/pdf/DataCite_FreDoc.pdf
Herbert Gruttemeier, INIST/ CNRS
Frédocs2013 - Gestion et valorisation des données de la recherche -  7 au 10 octobre 2013, Aussois

Cette présentation est consacrée au service proposé par **DataCite**. Herbert Gruttemeier explique pour commencer ce qu’est un DOI (dentifiant  persistant qui permet la citation et fournit un lien stable vers des ressources numériques,  comme les données de la recherche) et le **principe de citation, pourquoi utiliser un DOI**,  **comment le DOI s’inscrit dans le system Handle**. 

Il aborde la question de la **qualité des DOI** qui nécessite la mise en place d’une politique institutionnelle. La suite 
de son exposé est consacré à la **présentation de  DataCite**, Consortium international porté par des institutions locales, créé officiellement à Londres en décembre 2009. 
Il présente les 26 membres, la structure, les différents rôles qui lui sont assignés (agence d’attribution de DOI et agence de donnée). 

**Pourquoi citer les données ? **

H. Gruttemeier illustre ses propos par des exemples de jeux de donnés exposés et cités dans différents entrepôts. Il présente la **position « officielle » des éditeurs sur l’accès aux données de la recherche**
 et s’attarde sur le **type de données et de ressources concernés** par l’attribution de DOI. Data Cite propose un certain nombre 
de **services** (création de différents formats de citation pour les DOI, exposition des métadonnées, schéma de métadonnées dataCite et un environnement de test) que l’auteur détaille. Il est question aussi de **« Data Citation Index »** et de métrique, de l’importance d’accéder à la découverte des données (principe de moissonnage des 
métadonnées DataCite), **des partenariats** avec ORCID, OPENAIR, CODATA, FORCE 11, RDA …

### Retour d'expériences d'utilisation de DOI:

[rajouter du texte sur ces presentatinos] 
* Mise en place d'un DOI sur les données d'un réseau d'observations océanographiques
<https://sist16.sciencesconf.org/data/pages/16\_P\_Techine.pdf>                                 
Philippe Téchiné, Laboratoire d'études en Géophysique et océanographie spatiales                      

* Création de DOI sur les données et produits grillés du Service National d'Observation SSS
<https://sist18.sciencesconf.org/data/pages/14\_P\_Techine\_DOI\_sur\_les\_donnees\_du\_SNO\_SSS.pdf>
<http://rbdd.cnrs.fr/IMG/pdf/techine\_doi\_sss.pdf?525/cde234e7d87d1df64fffd20e8765ab33ca37f7b9>                                     
Philippe Téchiné, Laboratoire d'études en Géophysique et océanographie spatiales

Juliette Fabre et Olivier Lobry nous indique leur solution pour attribuer des DOI aux jeux de données du Service National d'Observation  "karst"
* Retour d'expérience sur l'attribution de DOI à l'OSU OREME. 
<https://sist16.sciencesconf.org/data/pages/17_O_Lobry.pdf>       
Juliette Fabre, OSU OREME - Olivier Lobry, OSU OREME  - Séminaire SIST2016 Montpellier 

Dans cette présentation Annick Battais indique comment assigner un D.O.I a des jeux de données dans le logiciel de catalogage Geonetwork.
* Utilisation d'un outil de catalogage normalisé ISO19139 comme GeoNetwork pour constituer une "landing page" pour un D.O.I
<https://sist19.sciencesconf.org/data/pages/SIST19\_A\_BATTAIS.pdf>

* Patrimoine scientifique en danger : des solutions d'avenir existent déjà.   
<https://sist16.sciencesconf.org/data/pages/18\_M\_Massol.pdf>
Marion MASSOL, CINES

* MCQ établissemnt de DOI sur des requetes dynamiques sur des Bases de données


Dans l'Infrastructure de Recherche "Data Terra" , le pôle de données Odatis fournit un service de D.O.I pour les données
marines <https://www.seanoe.org/>

* Le GBIF et les identifiants persistants : Application des DOI aux jeux de données, Sophie Pamerlon (Système mondial d’information sur la biodiversité - Global Biodiversity Information Facility), 2015
  * présentation : <http://rbdd.cnrs.fr/IMG/pdf/ipt_doi_rbdd.pdf?137/a5e7031e901f58c648f3f12eff64396a7b34a169>
  Sophie Pamerlon rapelle les définitions des identifiants uniques et persistants, puis présente le "Integrated Publishing Toolkit" (IPT) mis en place par le GBIF dans le domaine de la biodiversité et ses nouvelles fonctionnalités, en particulier l'attribution de DOI lors de la publication d'un jeu de données.

### La certification des entrepôts de données

Pour être digne de confiance les entrepots doivent répondre à certains prérequis et spécifications, lesquelles selon le besoin, peuvent amener à une certification.

CoreTrustSeal est un organisme communautaire sans but lucratif qui promeut le développement d'infrastructures de données durables et fiables et spécifient les criteres de conformité qui peuvent certifier un entrepôt

la [Research Data Alliance](https://www.rd-alliance.org/) s'appuye sur les criteres de conformités qui spécifient un entrepot de confiance : https://www.rd-alliance.org/coretrustseal-criteres-de-conformite

Dans le cadre des [séminaires du réseau SIST](https://sist.cnrs.fr/les-seminaires), Aude Chambodut nous présente "Pourquoi et comment aller vers la certification Core Trust Seal ?"
https://sist20.sciencesconf.org/program  [mettre le lien exact]


## Déposer/Publier dans des entrepôts institutionnels

[CH- *Peut-être dans cette partie privilégier un contenu qui informe sur les précautions à prendre pour déposer, choisir l'entrepôt qui va bien et parler de la certification plutôt que l'énumération d'infrastructures disponibles disponible dans Imaginer et la page infrastructure*]
[les 2 me semblent importants, mais  il faut compléter en ce sens, avec la FAQ de la journee entrepot]

**Déposer dans des Entrepôts.. lesquels? comment?**


Dans le cadre de la Science ouverte, un certain nombre d'entrepots se mettent en place au niveau national. 

Déposer dans des entrepôts institutionnel nécessite un certain nombre de prérequis : 
- avoir des données, validées et présentant un code qualité renseignant sur la
- avoir des métadonnées descriptives bien renseignées et faisant partie d'un thesaurus identifié
- si nécessaire certifier le centre de dépôt avec la certification "Core Trust Seal" par exemple

L'infrastructure de données Européenne Seadatanet fournit par exemple une [table "L20" fournissant les codes qualités](https://vocab.seadatanet.org/v_bodc_vocab_v2/browse.asp?order=conceptid&formname=search&screen=0&lib=l20&v0_0=&v1_0=conceptid%2Cpreflabel%2Caltlabel%2Cdefinition%2Cmodified&v2_0=0&v0_1=&v1_1=conceptid&v2_1=3&v0_2=&v1_2=preflabel&v2_2=3&v0_3=&v1_3=altlabel&v2_3=3&v0_4=&v1_4=modified&v2_4=9&v0_5=&v1_5=modified&v2_5=10&x=27&y=12&v1_6=&v2_6=&v1_7=&v2_7=) à placer sur les données 
 

### Les Infrastructures de Recherche nationales

Le [Ministère  de l'Enseignement supérieur, de la Recherche et de l'Innovation](https://www.enseignementsup-recherche.gouv.fr) tient à jour la liste officielle des [Infrastructures de Recherche nationales](https://www.enseignementsup-recherche.gouv.fr/cid70554/la-feuille-de-route-nationale-des-infrastructures-de-recherche.html).

Parmi elles certaines infrastructure ont des feuilles de route 

### Les pôles de données en Environnement
  
La mission de [l’IR Data Terra](https://www.data-terra.org/) consiste à organiser de manière intégrée la diffusion et l’accès aux données, en mettant à disposition les données, les produits et des services relatifs à l’observation du système Terre, via les pôles de données et de services existants :


* Présentation de l'IR Data terra
Richard Moreno, directeur technique
Séminaire SIST 2019, OMP Toulouse
https://sist19.sciencesconf.org/data/pages/SIST19_Poles_IRDataTerra.pdf


* <https://www.data-terra.org/>La **mission principale** des 4 Pôles (ODATIS, AERIS, ForM@Ter \& Theia) de l’IR Data Terra est de **mettre à disposition** des **données**, des **produits**, des **logiciels**, des **outils** et/ou des **services** destinés en premier lieu **à la communauté scientifique française** dans le cadre de ses **recherches sur le système Terre**. Les informations proposées par les pôles de données sont aussi fondamentales pour la **mise en œuvre des politiques publiques**. En permettant de mieux comprendre la structure et le fonctionnement du système Terre, les travaux utilisant ces données ont un **impact socio-économique** important dans des domaines tels que les risques naturels, le changement climatique, les ressources minérales ou les ressources en eau. Dans ce contexte, les **pôles servent aussi la communauté internationale** (missions satellites, réseaux d’observations internationaux, partenariats pour le développement).

   * Données océanographiques  <https://www.odatis-ocean.fr/>
     * https://sist19.sciencesconf.org/data/pages/SIST19_Poles_ODATIS.pdf
   * Données atmosphériques : <https://www.aeris-data.fr/>
     *  https://sist19.sciencesconf.org/data/pages/SIST19_Poles_AERIS.pdf
   * Données terre solide:  <https://www.poleterresolide.fr/>
     * https://sist19.sciencesconf.org/data/pages/SIST19_Poles_FORMATER.pdf
   * Données surfaces continentales : <https://www.theia-land.fr/>
     * https://sist19.sciencesconf.org/data/pages/SIST19_Poles_THEIA.pdf
   




### Les entrepôts de données

Dans un contexte de sciences ouvertes, les acteurs de la recherche s'accordent aujourd'hui pour considérer les données de la recherche comme des produits de la recherche et appellent à mieux les gérer et à les partager. En france, la loi CADA modifiée par la loi Valter le 28 décembre 2012 incite à mettre les données de la recherche à disposition sous format ouvert et librement réutilisable. Les enjeux liés à la gestion et au partage des données de la recherche nécessitent des outils appropriés.  Mais qu'est-ce qu'un entrepôt de données et quelles en sont les principales caractéristiques ? Comment les entrepôts de données contribuent-ils à la gestion et au partage des données? 

Qu'est-ce qui différencie un entrepôt de données d'une base de données classique dans le contexte de l'ouverture des données ? Quels
services peut-on attendre d'un entrepôt de données aux différentes étapes du cycle de vie de la donnée? Comment trouver et choisir
un entrepôt de données ?

Dans cette présentation générale sur les entrepôts de données Laurent PELLETIER, INIST,revient sur les différentes définitions des données, les métadonnées et les principes FAIR. Il explique pourquoi et comment partager les données et comment les entrepôts de données sont impliqués dans ce partage. Il présente les différents types d'entrepôts, les différentes fonctionnalités et les critères de choix pour un entrepôt.

* Les *entrepôts* de données, 
  * Laurent PELLETIER, INIST
  * <http://rbdd.cnrs.fr/IMG/pdf/20181029-jrbdd-presentationentrepotdonnees.pdf?516/9dc0c4b9f755d121305cf83c440d1d8faed96d73>
     

* Les entrepôts de données : pierre angulaire du partage des données de la recherche - Ester Dzale Yeumo (INRA) - Participer à l'organisation du management des données de la recherche : gestion de contenu et documentation des données -  6-8 juil. 2016 Paris (France)                             
<https://anfdonnees2016.sciencesconf.org/resource/page/id/1>


* Entrepôts de données - Sylvie Cocaud (INRA) - Participer à    l'organisation du management des données de la recherche : gestion
   de contenu et documentation des données -  3-6 juil. 2017 Paris    (France)
ppt -  <https://anfdonnees2017.sciencesconf.org/data/pages/Entrepots\_ANFRenatis\_2017\_Cocaud\_Aventurier\_1.pdf>


* rajouter la presentation de JC Desconnet de SIST 2020 [lien]


## Publier un "Datapaper" pour valoriser et expliciter les données

Le data paper est un article scientifique : il permet de décrire un jeu de données de recherche (data, dataset), à l’aide d’informations plus précises et détaillées que celles qu'on peut trouver dans un DMP, notamment en insistant sur :

- les aspects méthodologiques,
- la qualité des données et de leur méthode de collecte et de traitement.
- l’originalité et la portée de ce jeu de données, ainsi que leur potentiel pour des utilisations futures (arguments décisifs pour l'acceptation de la publication).
- l'accès au jeu de données, dans un fichier attaché ou par un lien pérenne (URL, DOI) vers un entrepôt où le jeu est déposé et accessible.

Publier un data paper permet de :

- valoriser les données 
- faciliter leur réutilisation 
- leur apporter de la visibilité
- les rendre plus facilement repérables et citables; le data paper étant une publication citable, au même titre que tout article scientifique, il met en valeur ses auteurs en tant que créateurs de données et permet la traçabilité des citations et des réutilisations.

Le data paper est publié, en libre accès, sous la forme d'un article examiné par les pairs dans une revue scientifique classique publiant différentes formes d’articles, dont des data papers, ou dans un data journal, c’est-à-dire une revue contenant exclusivement des data papers.  Des listes de revues publiant des data papers sont disponibles sur :

* Data papers : Une incitation à la publication de données sur la biodiversité, Sophie Pamerlon (Système mondial d’information sur la biodiversité - Global Biodiversity Information Facility)
 * transparents de la présentation : <http://rbdd.cnrs.fr/IMG/pdf/data-papers-rbdd.pdf?136/a3858796a8f136546895fd84a9fc34f24e62a842>

Après avoir expliqué pourquoi le GBIF et l’éditeur de revues PENSOFT ont proposé le concept de data paper, Sophie Pamerlon en explique les avantages et à travers quelques exemples concrets comment les outils du GBIF facilitent la rédaction d'un datapaper en biodiversité.


* Du Plan de Gestion des Données au Datapaper : suivi des données scientifiques tout au long de leur cycle de vie
  * Wilfried Heintz, UMR 1201 Dynafor
  * transparents : <https://sist18.sciencesconf.org/data/pages/16_W_Heintz_Du_plan_de_gestion_des_donnees_au_data_paper.pdf>

* Gestion pérenne des données scientifiques : du plan de gestion de données au datapaper.
  * HEINTZ, Wilfried, Storage Day 2018, Paris.
  * <http://rbdd.cnrs.fr/IMG/pdf/sd2018_datamanagement_wheintz.pdf?435/8949f16992fdffdffe7b7ef53258e71f9500c685> 
  
  Ce retour d'expérience sur tout le cycle de vie des données est relatif au domaine de la biodiversité.

## Publier des données grâce au web des données et au web sémantique 

[manque un peu de texte introductif ici]

* Rendre nos Données Accessibles et Interopérables sur le Web, 
http://rbdd.cnrs.fr/IMG/pdf/rbdd15_-_rendre_nos_donnees_accessibles_et_interoperables_sur_le_web.pdf?122/a040d4391568c6a41ec2da15ce602e0ec0faa20c
Franck Michel (I3S - UMR 7271, CNRS - Univ. Nice Sophia), 2015
mots-clés : SPARQL, web sémantique, RDF, SKOS, OWL

Rendre les données interopérables sur le web est le sujet essentiel de cette présentation très complète. Après avoir posé le contexte, Franck Michel développe le sujet en déroulant le plan suivant :
  - The Web of Data and the Semantic Web
  - Create, reuse and link vocabularies
  - Populate the Web of Data
  - Publish Linked Open Data on the Web

Il détaille le modèle RDF (Resource Description Framework) du W3C, puis, le langage de requêtes SPARQL. Il explique ensuite le standard SKOS (Simple Knowledge Organization System) utilisé pour représenter les vocabulaires contrôlés, les taxonomies et thesauri. Il termine en montrant comment publier des données ouvertes sur le web.

* Atelier « Mise en place d’un SPARQL EndPoint. Servir du RDF via HTTP avec Jena et Fuseki », Wilfried Heintz (Unité Mixte de Recherche « Dynamiques et écologie des paysages agriforestiers), 2015
  * lien vers la présentation : http://wheintz.github.io/jRBDD1015.html#1
  
Cet atelier technique est organisé selon le plan suivant :
  - Présentation de l'outil Jena
  - Pré-requis et préparation du serveur
  - RDFizer les métadonnées ou les données
  - Installation de Fuseki
  - Exemples d'exploitation du Sparql Endpoint


[ca fini en queue de poisson...est ce qu'on fait u nparagraphe de conclusion sur le chapitre 7 publier]

Tous les éléments exposés dans ce chapitre sont nécessaires et important pour concourir a une bonne publication et diffusion des données de la science.

