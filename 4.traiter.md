# Traiter les données

Cette phase du cycle de vie des données correspond au pré-traitement des données brutes issues des acquisitions et des collectes.
Il s'agit souvent de regrouper, choisir, qualifier les données pertinentes, les reformater dans des formats standards interopérables, et les préparer en vue de leur analyse.

Cette partie est donc structurée en différentes sections décrivant cette préparation des données :

- Préparer les fichiers de données, en vue de leur analyse, en utilisant des formats interopérables
- Utiliser des framework d'intégration de données si besoin lorsqu'elles sont hétérogènes
- Mettre en place ou utiliser des plateformes de gestion de données locales, en vue de leur analyse
- Vérifier et s'assurer de la qualité des données


## Préparer les fichiers de données en vue de leur analyse

**Mise en forme des données dans des formats standards, interopérables**

Bien souvent, les données primaires sont issus d'instruments, de collecte sur le terrain, ... et se présentent sous la forme de fichiers aux formats propriétaires ou peu interopérables.

Il est important de se préoccuper du format des données afin qu'ils soient interopérables, et à cet effet, le site Doranum propose une [introduction à la définition de formats ouverts ou fermés](https://doranum.fr/stockage-archivage/quiz-format-ouvert-ou-ferme/).

De plus, si l'objectif est le traitement massif des données, il est important de choisir des formats capables de supporter des entrées / sorties intensives sur des infrastructures de calcul.

### utiliser des formats standards 

Parmi les premiers traitements opérés sur des données brutes provenant du terrain, on doit fréquemment filtrer, extraire les données utiles dans des fichiers issus des acquisitions par des capteurs qui sont souvent peu exploitables dans leur état originel.

Les données issues de capteurs environnementaux sont fréquemment dans des formats propriétaires, souvent illisibles et peu exploitables par un être humain. Il convient alors de traiter les fichiers bruts de manière à en extraire les données utiles et les réécrire dans des formats standards utilisables par un grand nombre de logiciels, et une communauté d'utilisateurs.

- **Le format de fichier [NetCDF]** (https://www.unidata.ucar.edu/software/netcdf/) est un format ouvert, auto-documenté et très utilisé en particulier dans les communautés sciences de l'environnement par exemple pour formater des données en océanographie, météorologie, atmosphère.

Le format NetCDF  permet d'insérer les métadonnées dans une entete du fichier, avec les données elles mêmes.
On peut ainsi décrire de manière assez précise les données du fichier, par exemple en insérant les unités de mesure des parametres mesurés, la licence de diffusion, les propriétaires etc, ainsi que l'organisation des données (point, profil, série, trajectoire...), sans avoir besoin d'un fichier de description complémentaire. 

Toutefois dans son format originel NetCDF n'impose rien comme metadonnées, et on peut y mettre ce qu'on veut comme libellé de variables, unités, tc., ce qui nécessite donc une standardisation des métadonnées NetCDF. 

Dans les domaines océan, atmosphère par exemple, il est recommandé d'utiliser la [convention CF (climate forecast)](https://cfconventions.org/) qui propose une sandardisation des métadonnées inscrites dans une entête NetCDF.

Ce format est préconisé par le pôle de données Odatis et a été présenté au [séminaire SIST19 à l'OMP](https://sist19.sciencesconf.org) de Toulouse, par Joel Sudre, maurice Libes et Didier Mallarino :

* [Présentation du format NetCDF](<https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_JS.pdf>)   
Joël Sudre, LEGOS   

* [La convention CF (climate forecast) pour les fichiers NetCDF](https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_CF_ML.pdf)   
Joël Sudre, LEGOS et Maurice Libes, Institut Pytheas   

* [Utilisation de l'API de programmation Python pour NetCDF](<https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_python.pdf>)   
Maurice Libes, Didier Mallarino, Institut Phyteas   

- **Le format ODV** (ocean data view) [https://odv.awi.de/](https://odv.awi.de/)  est également un format standard ouvert intéressant. Il se rapproche d'un format CSV, composé de colonnes de données séparées par des virgules (ou tout autre séparateur), à cette différence près que le format ODV permet l'insertion d'une entête assez riche permettant de placer des métadonnées en début de fichier.

Les formats NetCDF et ODV sont les formats recommandés et utilisés par le pôle de données Odatis  <https://www.odatis-ocean.fr/donnees-et-services/principes-de-gestion-des-donnees/formats-attributs-conventions> et par le projet Européen Seadatanet <https://www.seadatanet.org/>.

- **Le format HDF5**

Le format [HDF5](https://www.hdfgroup.org/solutions/hdf5/) (Hierarchical Data Format, version 5) est un format de fichier de type conteneur, c'est-à-dire assimilable à une arborescence de dossiers / fichiers contenu dans un même fichier.

C'est un format très utilisé lorsqu'on veut traiter ou simuler des données grâce au calcul intensif car il offre des possibilité de compression et d'écriture/lecture parallèles très efficaces.

Des supports de formation sur ce format sont de ce fait disponibles via les infrastructures et réseaux en lien avec le calcul intensif :

- HDF5 : theory & practice [1](https://materials.prace-ri.eu/386/6.haslightboxThumbnailVersion/hdf51.pdf) et [2](https://materials.prace-ri.eu/386/7.haslightboxThumbnailVersion/hdf52.pdf)   

- Prace Advanced Training Centers, [Course: Parallel I/O and management of large scientific data, 2014](https://materials.prace-ri.eu/386/)



## Organiser les données

### Utiliser un framework d’agrégation de données

Lorsque les données à traiter sont hétérogènes et que les technologies qui permettent de les fournir sont également différentes, une solution est d'utiliser un "framework" d’agrégation de données comme Lavoisier. 

Ce logiciel, développé au CC-IN2P3, permet de récupérer, transformer,  fusionner, et requêter des données de sources différentes. 

- [Lavoisier : un framework d'agrégation de données](https://jcad2018.sciencesconf.org/data/jcad2018_lavoisier_2_.pdf),  [vidéo de la présentation](https://webcast.in2p3.fr/video/lavoisier-un-framework-dagregation-de-donnees-1)    
Cyril L'Orphelin, Sylvain Reynaud, CC-IN2P3, CNRS   
JCAD 2018    

D'autres outils existent, permettant l'intégration de données, dans la catégorie des ETL (Extract, Transform, Load). Le logiciel Talend Open Studio par exemple, a été abordé lors d'une session de formation du réseau RBDD :

- ["Utilisation et maîtrise d'un ETL : intégrations de données avec Talend Open Studio"](http://rbdd.cnrs.fr/spip.php?article215)
Eric Quinton  
Réseau RBDD, 2017   

Cet ETL "Talend" a été également utilisé par Soumaya Lahbib pour traiter les données des capteurs du [projet EMSO Ligureouest](https://www.osupytheas.fr/?Presentation-du-projet-EMSO)

[Gestion des données du projet EMSO avec Talend et Erddap](https://sist18.sciencesconf.org/data/pages/05_M_Libes_Getsion_des_donnees_EMSO.pdf)    
Maurice Libes, Soumaya Lahbib   
[Séminaire SIST18 OVSQ](https://sist18.sciencesconf.org)   

### Déposer et structurer dans des plateformes de gestion de données locales

Les services informatiques de certains laboratoires de recherche et en particulier des OSU ("Observatoires des Sciences de l'Univers") ont pour vocation et pour mission d'intervenir dans la gestion des données d'observation acquises sur le terrain.  Après la phase de collecte de données que nous avons vue dans l'étape précédente du cycle de vie des données, il est nécessaire de se préoccuper de la facilité d'accès et de la réutilisation des données localement dans une unité de recherche.

Un certain nombre de logiciels font office de plateforme d'accès et de gestion des données. Ils permettent de présenter les données avec leur métadonnées, de fournir des interfaces de recherche, de géolocaliser les données, et parfois de visualisation des données avec des graphes. Cette organisation des données facilite grandement leur analyse ultérieure.

Des logiciels sont particulièrement adaptés dans la diffusion et l'affichage des données scientifiques d'observation par le fait qu'ils utilisent les standards interopérables de l'Open Geospatial Consortium (OGC), ISO19139, Inspire, etc)



*  le serveur cartographique *[Geoserver](http://geoserver.org/)* permet d'afficher et permettre les échanges de données géospatiales sur le web selon les standards (WMS, WFS, ...) de l'OGC ;
  
*  l'application GeoCMS et [GeoOrchestra](https://www.georchestra.org/) permettent la visualisation de données géospatiales sur le web et de mettre en place une Infrastructure de Données Géographique (IDG) ;
   
*  Les plateformes de diffusion de données comme [Thredds](https://www.unidata.ucar.edu/software/tds/) et [Erddap](https://coastwatch.pfeg.noaa.gov/erddap/index.html) sont des solutions très bien  adaptées pour rendre les données FAIR et en faciliter la diffusion des données.

La plateforme d'accès ERDDAP se présente comme un accès facile aux données scientifiques ("Easier access to scientific data") et fournit un ensemble complet de fonctionnalités pour la gestion des jeux de données. Il permet :
* de lire et écrire des jeux de données dans de nombreux formats standards interopérables différents,
* de fournir un catalogue des jeux de données gérés par le serveur
* d'afficher les metadonnées inscrites dans les fichiers
* d'interroger et filtrer les données au travers de formulaires,
* de créer des graphiques et des cartes simples pour visualiser le jeu de données analysé
* de normaliser le format des unités de temps présentes dans les fichiers

Une des fonctionnalités intéressantes est que Erddap agrège automatiquement les données nouvelles répondant a un format donné, qui sont déposées dans un répertoire. Ainsi pour les séries temporelles cette fonctionnalité est intéressante puisqu'il suffit de déposer des fichiers dans un répertoire pour que la série soit automatiquement enrichie et mise à jour.


#### Exemple de mise en oeuvre de plateformes de données

Des exemples d'utilisation des plateformes logicielles Erddap et Thredds ont été présentés à différentes session des journées du réseau SIST :

* [Distribution et visualisation de données avec Thredds, exemples d'utilisation au SEDOO ](https://nuage.osupytheas.fr/index.php/s/ROh4LCpHZCWdlHz#pdfviewer)     
Guillaume Brissebrat, Service de données de l'OMP   
[Séminaire SIST 2015 OSU Pytheas Marsielle](https://sist15.sciencesconf.org/)    


- [Copier les succès et rester simple (AMEO) : Mise à disposition de sorties de modèles climatiques avec un NAS, THREDDS et ERDDAP.](https://sist16.sciencesconf.org/data/pages/11_T_Valero_F_Bongat.pdf)    
Thierry Valéro, Institut de Recherche pour le Développement, Laboratoire d'Océanographie et du Climat   
[Séminaire SIST 2016 OSU OREME Montpellier](https://sist16.sciencesconf.org/)    

- [Gestion des données du projet EMSO avec Talend et Erddap](<https://sist18.sciencesconf.org/data/pages/05_M_Libes_Getsion_des_donnees_EMSO.pdf>)   
Soumaya Lahbib, Maurice Libes, OSU Pytheas  
[Séminaire SIST 2018 OVSQ](https://sist18.sciencesconf.org/)   

* [Eccad, un exemple de mise en oeuvre de Thredds](https://sist19.sciencesconf.org/data/pages/SIST19_S_Darras.pdf)   
Sabine Darras, Observatoire Midi-Pyrénées   
[Séminaire SIST 2019 OMP Toulouse](https://sist19.sciencesconf.org/)   

Les événements suivants fournissent  un certain nombre de connaissances sur l’utilisation d'infrastructure
de données géographiques (IDS, IDG) et de plateforme logicielles de gestion des données

*  [Infrastructure de données spatiales et de traitements GEOSUD : des standards à la réalité](https://sist16.sciencesconf.org/data/pages/01_JC_Desconnets.pdf)      
Jean-Christophe Desconnets, UMR Espace-Dev, IRD   
[Séminaire SIST 2016 OSU OREME Montpellier](https://sist16.sciencesconf.org/)   
   

* [Publication automatique de données et de métadonnées dans geOrchestra](https://sist18.sciencesconf.org/data/pages/19_E_Chiarello_GeOrchestra.pdf) 
Ernest Chiarello, Théoriser et modéliser pour aménager, MSHE
[Séminaire SIST 2018](https://sist18.sciencesconf.org/)

Loic Salaun nous montre un exemple de consultation des données à partir d’un visualiseur cartographique (visualiseur d’INDIGEO), utilisant les services web géographiques (WMS, WFS, WCS, CSW)
* [Mise en place d'une IDS pour le programme de recherche Réseau de Suivi et de Surveillance de l'Environnement.](https://sist16.sciencesconf.org/data/pages/02_L_Salaun.pdf)   
Loïc Salaun, Observatoire des Sciences de l'Univers Nantes Atlantique   
[Séminaire SIST 2016](https://sist16.sciencesconf.org)   

 

## Mettre en place un contrôle qualité des données

Par nature, la recherche n’est pas répétitive mais riche en incertitudes contrairement à un processus industriel. 
La confiance dans la qualité d’une recherche consiste donc à établir et vérifier que les différentes étapes d’une étude peuvent être répétées en obtenant le même résultat par des chercheurs différents à des moments différents. Ainsi, une donnée est fiable si, dans des conditions données, aucune déviation n’est constatée en fonction du temps, durant un laps de temps donné. 
Il est donc essentiel de s’assurer que l’ensemble des activités de recherche soit maîtrisée. 

Le contrôle sur les équipements est le premier pas vers la traçabilité des données comme l'illustre l'exposé suivant :

* [Traçabilité des données de la recherche. Confirmation métrologique des équipements](https://qualsimp.sciencesconf.org/data/program/9_Trac_abilite_des_donne_es_de_la_recherche_Virginie_JAN_LOGASSI.pdf)  
Virginie JAN LOGASSI, Université de Lorraine  
[Rencontres du réseau Qualité en Recherche, 2019](https://qualsimp.sciencesconf.org/)  

Plusieurs présentations et ateliers sur ce thème ont eu lieu lors de l'ANF "[Sciences des données : un nouveau challenge pour les métiers liés aux bases de données](http://rbdd.cnrs.fr/spip.php?article288)" en 2018 à Sète. En particulier l'Atelier qualité des données dont les travaux portaient sur les questions suivantes :

- Une explicitation des notions autour de la [qualité des données](http://rbdd.cnrs.fr/IMG/pdf/qualite_des_donnees_plumejeaud_2018_04112018.pdf?517/365a13edab604bd0700b045bfac29a3607acb649)   
Christine Plumejeaud, Nadine Mandran   

- Une [présentation autour de l'outil OpenRefine de nettoyage et mise en forme des données.](http://rbdd.cnrs.fr/IMG/pdf/openrefinecours.pdf?518/a69ce451abd02003a0e96957e39828e0f2e9f2ee)   
Mathieu SABY, BU Université de Nice Sophia-Antipolis  

D'autres interventions concernant la validation des données de terrain, et leur intégration apportent un point de vue différent :

- [Outils nomades : validation des données](http://rbdd.cnrs.fr/IMG/pdf/anf_rbbd_2019_outils_mobiles_tp_qualite.pdf?573/e1425561fd10c6bd1dd92fdee22871bc427f9873)   
Christine Plumejeaud-Perreau, CNRS, U.M.R 7266 LIENSs, la Rochelle   
ANF "Interfacer les outils mobiles avec son système d’information", réseau RBDD, 2019   

- [Retour terrain : la délicate question de l’intégration des données](http://rbdd.cnrs.fr/IMG/pdf/anf2019_seshat.pdf?576/575888582b8771a01200c5a6a5e751f0964e0c33)   
Pierre-yves Arnould, CNRS, OTELo   
ANF "Interfacer les outils mobiles avec son système d’information", réseau RBDD, 2019   

### L'exemple des sciences environnementales

En sciences environnementales, on retrouve de nombreuses méthodes pour essayer de qualifier les données, illustrées par les exposés suivants donnés lors des journées de séminaires SIST (Séries Interopérables et Systèmes de Traitement) du réseau technologique des informaticiens et gestionnaires de données des observatoires :

 * [Suivi de la qualité des mesures de réseaux d'observations océanographiques](https://sist16.sciencesconf.org/data/pages/09_P_Techine.pdf)
Philippe Téchiné, B. Buisson, L. Testut, T. Delcroix, G. Alory, Laboratoire d'études en Géophysique et océanographie spatiales
[Séminaire SIST 2016 Montpellier](https://sist16.sciencesconf.org/)

 * [Site Web de diffusion des données "Sahelian Dust Transect"](https://sist16.sciencesconf.org/data/pages/10_A_Campos.pdf)  
André CAMPOS, Laboratoire inter-universitaire des systèmes atmosphériques   
[SIST 2016](https://sist16.sciencesconf.org/)      

* [ATCQc : Un outil pour le QA/QC de mesures atmosphérique du TGIR ICOS](https://sist18.sciencesconf.org/data/pages/29_L_Hazan_ATCQc.pdf), [vidéo](https://sist18.sciencesconf.org/data/pages/29_L_Hazan_ATCQc.mp4)   
Lynn Hazan, Laboratoire des Sciences du Climat et de l'Environnement   
[Séminaire SIST 2018 OVSQ ](https://sist18.sciencesconf.org/)

* [La qualité des données à l'OSU OREME](https://sist18.sciencesconf.org/data/pages/31_F_Fabre_O_Lobry_Qualite_des_donnees_de_l_OSU_OREME_.pdf)   
Juliette Fabre, Olivier Lobry, Observatoire de REcherche Méditerranéen de l'Environnement   
[Séminaire SIST 2018](https://sist18.sciencesconf.org/)   

Certains logiciels comme ODV (Ocean Data view)  permettent de qualifier les données et d'attribuer un code qualité a des données après analyse par un expert du domaine.
ODV est un format de fichiers, et un logiciel utilisés par le projet Européen [SeadataNet](https://www.seadatanet.org/Software/ODV). 



### Développer les procédures d'intégration des données dans les bases de données     -> qualité ?                  

[ML: manque du texte explicatif et introductif ici]

*  [Intégrer les données dans sa base métier](http://rbdd.cnrs.fr/IMG/pdf/integrer_donnees.pdf?570/2006217c4509e4d59e6cbf44a291f997e7500153)   
MC. Quidoz   


*  [UUID avec PostgreSQL : Pourquoi ? Comment ?](http://rbdd.cnrs.fr/IMG/pdf/uuid_postgres.pdf?405/e6315023727441ee71c5d63415dd28285bc24952)   
. Raidelet   

*  [Les avantages et les inconvénients de la solution ODK](http://rbdd.cnrs.fr/IMG/pdf/bilan_odk.pdf?579/014d2664a47a1b155dde7a4ce7cf84db388194fa)  
   MC. Quidoz \& PY. Arnould \& les stagiaires   

*  [Référence sur ODK](http://rbdd.cnrs.fr/IMG/pdf/bibliographie.pdf?571/bbecc7bd883e4751efb6ccba6f99517ded5a6305) 
MC. Quidoz   

*  [Outils nomades : validation des données](http://rbdd.cnrs.fr/IMG/pdf/anf_rbbd_2019_outils_mobiles_tp_qualite.pdf?573/e1425561fd10c6bd1dd92fdee22871bc427f9873)    
C. Plumejeaud   

*  [Retour terrain : la délicate question de l’intégration des données](http://rbdd.cnrs.fr/IMG/pdf/anf2019_seshat.pdf?576/575888582b8771a01200c5a6a5e751f0964e0c33)   
PY. Arnould   




### La gestion des collections 

Collec-Science (https://www.collec-science.org) est un logiciel web qui a été créé pour suivre les échantillons collectés lors des campagnes d’acquisition, et permet de répondre, entre autres, à ces questions :
    -   où est stocké l’échantillon ?
    -   d’où vient-il, quelle est sa généalogie (protocole de collecte, métadonnées associées à l’échantillon et ceux de ces ancêtres) ?
    -   quelles transformations ou opérations a-t-il subi ?
    -   sous quelle forme est-il conservé, existe-t-il un risque à le manipuler ?

Fruit d’une collaboration initiale entre Irstea (centre de Bordeaux), le laboratoire Epoc à Bordeaux, le LIENSs à La Rochelle, il a été enrichi avec la participation de nombreux autres laboratoires, dont les laboratoires Chrono-environnement à Besançon, Edytem à l’Université Savoie - Mont Blanc, etc. Il a été choisi par le Réseau des Zones Ateliers pour assurer le suivi des échantillons.

* [Stockez et retrouvez vos échantillons avec Collec-Science] (http://rbdd.cnrs.fr/spip.php?article304)   
Marie-Claude Quidoz   
