(traiter)=
# Traiter les données

Cette phase du cycle de vie des données correspond au prétraitement des données brutes issues des acquisitions et des collectes.
Il s'agit souvent de regrouper, choisir, qualifier les données pertinentes, les traiter les reformater dans des formats standards interopérables, et les préparer en vue de leur analyse.

Cette partie est donc structurée en différentes sections décrivant cette préparation des données :

- Préparer les fichiers de données, en vue de leur analyse, en utilisant des formats interopérables
- Utiliser des infrastructures logicielles ("framework") d'intégration de données, lorsqu'elles sont hétérogènes
- Mettre en place et utiliser des plateformes de gestion de données locales, en vue de leur analyse
- Vérifier et s'assurer de la qualité des données


## Préparer les fichiers de données en vue de leur analyse

Bien souvent, les données primaires sont issues d'instruments, de collecte sur le terrain ... et se présentent sous la forme de fichiers aux formats propriétaires peu interopérables.

Il est important de se préoccuper du format des données afin qu'ils soient ouverts et interopérables. À cet effet, le site Doranum propose une [introduction à la définition de formats ouverts ou fermés](https://doranum.fr/stockage-archivage/quiz-format-ouvert-ou-ferme/).

De plus, si l'objectif est le traitement massif des données, il est important de choisir des formats capables de supporter des entrées / sorties intensives sur des infrastructures de calcul.

### Utiliser des formats standards 

Parmi les premiers traitements opérés sur des données brutes provenant du terrain, les données issues de capteurs environnementaux sont fréquemment dans des formats propriétaires, souvent illisibles et peu exploitables par un être humain. Il convient alors de traiter les fichiers bruts de manière à en extraire les données utiles et les réécrire dans des formats standards utilisables par un grand nombre de logiciels, et une communauté d'utilisateurs.

Chaque discipline définit un certain nombre de formats standards.

Dans les domaines Océan, Atmosphère par exemple, le format [NetCDF](https://www.unidata.ucar.edu/software/netcdf/) est un format ouvert, autodocumenté et très utilisé en particulier dans les communautés sciences de l'environnement. Il est utilisé, par exemple pour formater des données qui sont issues de mesures sur le terrain et qui représentent des profils verticaux, des séries temporelles, ou encore des trajectoires. ce format permet de ne pas avoir besoin d'un fichier de description complémentaire, les métadonnées sont insérées dans l'entête du fichier, avec les données elles-mêmes.
On peut ainsi décrire de manière assez précise les données du fichier, par exemple en insérant les unités de mesure des paramètres mesurés, la licence de diffusion, les propriétaires, etc., ainsi que l'organisation des données.

Toutefois dans son format originel NetCDF n'a pas imposé des métadonnées, et il était possible d'inscrire n'importe quelle libellé de variables, unités, etc. Afin de proposer une standardisation, la  [convention CF (climate forecast)](https://cfconventions.org/) propose et fournit une standardisation des variables et unités de mesures à inscrire dans un fichier NetCDF.


Les formats NetCDF et ODV sont les formats recommandés et utilisés par le pôle de données Odatis  <https://www.odatis-ocean.fr/donnees-et-services/principes-de-gestion-des-donnees/formats-attributs-conventions> et par le projet européen Seadatanet <https://www.seadatanet.org/>, et  a été présenté au [séminaire SIST19 à l'OMP](https://sist19.sciencesconf.org) de Toulouse, par Joël Sudre, Maurice Libes et Didier Mallarino :

* [Présentation du format NetCDF](<https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_JS.pdf>)   
Joël Sudre, LEGOS   

* [La convention CF (climate forecast) pour les fichiers NetCDF](https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_CF_ML.pdf)   
Joël Sudre, LEGOS et Maurice Libes, Institut Pytheas   

* [Utilisation de l'API de programmation Python pour NetCDF](<https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_python.pdf>)   
Maurice Libes, Didier Mallarino, Institut Phyteas   

- **Le format ODV** (ocean data view) [https://odv.awi.de/](https://odv.awi.de/)  est également un format standard ouvert intéressant. Il se rapproche d'un format CSV, composé de colonnes de données séparées par des virgules (ou tout autre séparateur), à cette différence près que le format ODV permet l'insertion d'un entête assez riche permettant de placer des métadonnées en début de fichier.



- **Le format HDF5**

Le format [HDF5](https://www.hdfgroup.org/solutions/hdf5/) (Hierarchical Data Format, version 5) est un format de fichier de type conteneur, c'est-à-dire assimilable à une arborescence de dossiers / fichiers contenus dans un même fichier.

C'est un format très utilisé lorsqu'on veut traiter ou simuler des données grâce au calcul intensif, car il offre des possibilités de compression et d'écriture/lecture parallèles très efficaces.

Des supports de formation sur ce format sont de ce fait disponibles via les infrastructures et réseaux en lien avec le calcul intensif :

- HDF5 : theory & practice [1](https://materials.prace-ri.eu/386/6.haslightboxThumbnailVersion/hdf51.pdf) et [2](https://materials.prace-ri.eu/386/7.haslightboxThumbnailVersion/hdf52.pdf)   

- Prace Advanced Training Centers, [Course: Parallel I/O and management of large scientific data, 2014](https://materials.prace-ri.eu/386/)



## Organiser les données

### Utiliser un cadre d’applications d’agrégation de données

Lorsque les données à traiter sont hétérogènes et que les technologies qui permettent de les fournir sont également différentes, une solution est d'utiliser un "framework" d’agrégation de données comme Lavoisier. 

Ce logiciel, développé au CC-IN2P3, permet de récupérer, transformer,  fusionner, et requêter des données de sources différentes. 

- [Lavoisier : un cadre d’applications d'agrégation de données](https://jcad2018.sciencesconf.org/data/jcad2018_lavoisier_2_.pdf),  [vidéo de la présentation](https://webcast.in2p3.fr/video/lavoisier-un-framework-dagregation-de-donnees-1)    
Cyril L'Orphelin, Sylvain Reynaud, CC-IN2P3, CNRS   
JCAD 2018    

D'autres outils logiciels existent, permettant l'intégration de données. Dans la catégorie des logiciels "ETL" (Extract, Transform, Load, le logiciel "[Talend Open Studio](https://www.talend.com/fr/products/talend-open-studio/)" par exemple, a été abordé lors d'une session de formation du réseau RBDD :

- ["Utilisation et maîtrise d'un ETL : intégrations de données avec Talend Open Studio"](http://rbdd.cnrs.fr/spip.php?article215)
Eric Quinton  
Réseau RBDD, 2017   

Ce logiciel "Talend" a été également utilisé par Soumaya Lahbib pour traiter les fichiers de données issues des capteurs du [projet EMSO Ligure-ouest](https://www.osupytheas.fr/?Presentation-du-projet-EMSO) et les transformer en fichier CSV utilisable facilement.

* [Gestion des données du projet EMSO avec Talend et Erddap](https://sist18.sciencesconf.org/data/pages/05_M_Libes_Getsion_des_donnees_EMSO.pdf)    
Maurice Libes, Soumaya Lahbib   
[Séminaire SIST18 OVSQ](https://sist18.sciencesconf.org)   

### Déposer et structurer dans des plateformes de gestion de données locales

Les services informatiques de certains laboratoires de recherche et en particulier des OSU ("Observatoires des Sciences de l'Univers") ont pour vocation et pour mission d'intervenir dans la gestion des données d'observation acquises sur le terrain.  Après la phase de collecte de données que nous avons vue dans l'étape précédente du cycle de vie des données, il est nécessaire de se préoccuper de la facilité d'accès et de la réutilisation des données localement dans une unité de recherche.

Un certain nombre de logiciels font office de plateforme d'accès et de gestion des données. Ils permettent de présenter les données avec leurs métadonnées, de fournir des interfaces de recherche, de géolocaliser les données, et parfois de visualisation des données avec des graphes. Cette organisation des données facilite grandement leur analyse ultérieure.

Des logiciels sont particulièrement adaptés dans la diffusion et l'affichage des données scientifiques d'observation par le fait qu'ils utilisent les standards interopérables de l'Open Geospatial Consortium (OGC), comme le protocole DAP (Data Access Protocol) 

*  Les plateformes de diffusion de données comme [Thredds](https://www.unidata.ucar.edu/software/tds/) et [Erddap](https://coastwatch.pfeg.noaa.gov/erddap/index.html) sont des solutions très bien  adaptées pour rendre les données FAIR et faciliter la diffusion des données.

La plateforme d'accès ERDDAP se présente comme un accès facile aux données scientifiques ("Easier access to scientific data") et fournit un ensemble complet de fonctionnalités pour la gestion des jeux de données. Il permet :
* de lire et écrire des jeux de données dans de nombreux formats standards interopérables différents,
* de fournir un catalogue des jeux de données gérés par le serveur
* d'afficher les métadonnées inscrites dans les fichiers
* d'interroger et filtrer les données au travers de formulaires,
* de créer des graphiques et des cartes simples pour visualiser le jeu de données analysé
* de normaliser le format des unités de temps présentes dans les fichiers.

Une des fonctionnalités intéressantes est qu'Erddap agrège automatiquement les données nouvelles répondant a un format donné, qui sont déposées dans un répertoire. Ainsi pour les séries temporelles cette fonctionnalité est intéressante puisqu'il suffit de déposer des fichiers dans un répertoire pour que la série soit automatiquement enrichie et mise à jour.

On peut aussi déposer et faire gérer des données via des serveurs cartographiques comme :

*  le serveur cartographique [Geoserver](http://geoserver.org/) permet d'afficher et permettre les échanges de données géospatiales sur le web selon les standards (WMS, WFS, ...) de l'OGC ;
  
*  l'application GeoCMS et [GeoOrchestra](https://www.georchestra.org/) permettent la visualisation de données géospatiales sur le web et de mettre en place une Infrastructure de Données Géographique (IDG) ;
   

#### Exemple de mise en oeuvre de plateformes de données

Des exemples d'utilisation des plateformes logicielles Erddap et Thredds ont été présentés à différentes sessions des journées du réseau SIST :

* [Distribution et visualisation de données avec Thredds, exemples d'utilisation au SEDOO](https://nuage.osupytheas.fr/index.php/s/ROh4LCpHZCWdlHz#pdfviewer)     
Guillaume Brissebrat, Service de données de l'OMP   
[Séminaire SIST 2015 OSU Pytheas Marseille](https://sist15.sciencesconf.org/)    

- [Copier les succès et rester simple (AMEO) : mise à disposition de sorties de modèles climatiques avec un NAS, THREDDS et ERDDAP.](https://sist16.sciencesconf.org/data/pages/11_T_Valero_F_Bongat.pdf)    
Thierry Valéro, Institut de Recherche pour le Développement, Laboratoire d'Océanographie et du Climat   
[Séminaire SIST 2016 OSU OREME Montpellier](https://sist16.sciencesconf.org/)    

- [Gestion des données du projet EMSO avec Talend et Erddap](<https://sist18.sciencesconf.org/data/pages/05_M_Libes_Getsion_des_donnees_EMSO.pdf>)   
Soumaya Lahbib, Maurice Libes, OSU Pytheas  
[Séminaire SIST 2018 OVSQ](https://sist18.sciencesconf.org/)   

* [Eccad, un exemple de mise en oeuvre de Thredds](https://sist19.sciencesconf.org/data/pages/SIST19_S_Darras.pdf)   
Sabine Darras, Observatoire Midi-Pyrénées   
[Séminaire SIST 2019 OMP Toulouse](https://sist19.sciencesconf.org/)   


Les présentations suivantes fournissent  un certain nombre de connaissances sur l’utilisation d'infrastructure
de données géographiques (IDS, IDG) et de plateforme logicielle de gestion des données

*  [Infrastructure de données spatiales et de traitements GEOSUD : des standards à la réalité](https://sist16.sciencesconf.org/data/pages/01_JC_Desconnets.pdf)      
Jean-Christophe Desconnets, UMR Espace-Dev, IRD   
[Séminaire SIST 2016 OSU OREME Montpellier](https://sist16.sciencesconf.org/)   
   

* [Publication automatique de données et de métadonnées dans geOrchestra](https://sist18.sciencesconf.org/data/pages/19_E_Chiarello_GeOrchestra.pdf) 
Ernest Chiarello, Théoriser et modéliser pour aménager, MSHE
[Séminaire SIST 2018](https://sist18.sciencesconf.org/)

Loic Salaun nous montre un exemple de consultation des données à partir d’un visualiseur cartographique (visualiseur d’INDIGEO), utilisant les services web géographiques (WMS, WFS, WCS, CSW)
* [Mise en place d'une IDS pour le programme de recherche Réseau de Suivi et de Surveillance de l'Environnement.](https://sist16.sciencesconf.org/data/pages/02_L_Salaun.pdf)   
Loïc Salaun, Observatoire des Sciences de l'Univers Nantes Atlantique   
[Séminaire SIST 2016](https://sist16.sciencesconf.org)   

 

## Mettre en place un contrôle qualité des données

Par nature, la recherche n’est pas répétitive, mais riche en incertitudes contrairement à un processus industriel. 
La confiance dans la qualité d’une recherche consiste donc à établir et vérifier que les différentes étapes d’une étude peuvent être répétées en obtenant le même résultat par des chercheurs différents à des moments différents. Ainsi, une donnée est fiable si, dans des conditions données, aucune déviation n’est constatée en fonction du temps, durant un laps de temps donné. 
Il est donc essentiel de s’assurer que l’ensemble des activités de recherche soit maîtrisé. 

Le contrôle sur les équipements est le premier pas vers la traçabilité des données comme l'illustre l'exposé suivant :

* [Traçabilité des données de la recherche. Confirmation métrologique des équipements](https://qualsimp.sciencesconf.org/data/program/9_Trac_abilite_des_donne_es_de_la_recherche_Virginie_JAN_LOGASSI.pdf)  
Virginie JAN LOGASSI, Université de Lorraine  
[Rencontres du réseau Qualité en Recherche, 2019](https://qualsimp.sciencesconf.org/)  

Plusieurs présentations et ateliers sur ce thème ont eu lieu lors de l'ANF "[Sciences des données : un nouveau challenge pour les métiers liés aux bases de données](http://rbdd.cnrs.fr/spip.php?article288)" en 2018 à Sète. En particulier l'Atelier qualité des données dont les travaux portaient sur les questions suivantes :

- Une explicitation des notions autour de la [qualité des données](http://rbdd.cnrs.fr/IMG/pdf/qualite_des_donnees_plumejeaud_2018_04112018.pdf?517/365a13edab604bd0700b045bfac29a3607acb649)   
Christine Plumejeaud, Nadine Mandran   

- Une [présentation autour de l'outil OpenRefine de nettoyage et mise en forme des données.](http://rbdd.cnrs.fr/IMG/pdf/openrefinecours.pdf?518/a69ce451abd02003a0e96957e39828e0f2e9f2ee)   
Mathieu SABY, BU Université de Nice Sophia-Antipolis  

D'autres interventions concernant la validation des données de terrain, et leur intégration apportent un point de vue différent :

- [Outils nomades : validation des données](http://rbdd.cnrs.fr/IMG/pdf/anf_rbbd_2019_outils_mobiles_tp_qualite.pdf?573/e1425561fd10c6bd1dd92fdee22871bc427f9873)   
Christine Plumejeaud-Perreau, CNRS, U.M.R 7266 LIENSs, la Rochelle   
ANF "Interfacer les outils mobiles avec son système d’information", réseau RBDD, 2019   

- [Retour terrain : la délicate question de l’intégration des données](http://rbdd.cnrs.fr/IMG/pdf/anf2019_seshat.pdf?576/575888582b8771a01200c5a6a5e751f0964e0c33)   
Pierre-Yves Arnould, CNRS, OTELo   
ANF "Interfacer les outils mobiles avec son système d’information", réseau RBDD, 2019   

### L'exemple des sciences environnementales

En sciences environnementales, on retrouve de nombreuses méthodes pour essayer de qualifier les données, illustrées par les exposés suivants donnés lors des journées de séminaires SIST (Séries Interopérables et Systèmes de Traitement) du réseau technologique des informaticiens et gestionnaires de données des observatoires :

* [Suivi de la qualité des mesures de réseaux d'observation océanographique](https://sist16.sciencesconf.org/data/pages/09_P_Techine.pdf)   
Philippe Téchiné, B. Buisson, L. Testut, T. Delcroix, G. Alory, Laboratoire d'études en Géophysique et océanographie spatiales   
[Séminaire SIST 2016 OSU OREME Montpellier](https://sist16.sciencesconf.org/)   

* [Site Web de diffusion des données "Sahelian Dust Transect"](https://sist16.sciencesconf.org/data/pages/10_A_Campos.pdf)  
André CAMPOS, Laboratoire interuniversitaire des systèmes atmosphériques   
[SIST 2016 OSU OREME Montpellier](https://sist16.sciencesconf.org/)      

* [ATCQc : Un outil pour le QA/QC de mesures atmosphériques du TGIR ICOS](https://sist18.sciencesconf.org/data/pages/29_L_Hazan_ATCQc.pdf), [vidéo](https://sist18.sciencesconf.org/data/pages/29_L_Hazan_ATCQc.mp4)   
Lynn Hazan, Laboratoire des Sciences du Climat et de l'Environnement   
[Séminaire SIST 2018 OVSQ ](https://sist18.sciencesconf.org/)   

* [La qualité des données à l'OSU OREME](https://sist18.sciencesconf.org/data/pages/31_F_Fabre_O_Lobry_Qualite_des_donnees_de_l_OSU_OREME_.pdf)   
Juliette Fabre, Olivier Lobry, Observatoire de REcherche Méditerranéen de l'Environnement    
[Séminaire SIST 2018 OVSQ](https://sist18.sciencesconf.org/)    

Certains logiciels comme ODV (Ocean Data View)  permettent de qualifier les données et d'attribuer un code qualité a des données après analyse par un expert du domaine.
ODV est un format de fichiers, et un logiciel utilisés par le projet européen [SeadataNet](https://www.seadatanet.org/Software/ODV). 



### Développer les procédures d'intégration des données dans les bases de données     -> qualité ?                  

> ML: manque du texte explicatif et introductif, ici décoder si on laisse ou enlève ce passage]

*  [Intégrer les données dans sa base métier](http://rbdd.cnrs.fr/IMG/pdf/integrer_donnees.pdf?570/2006217c4509e4d59e6cbf44a291f997e7500153)   
MC. Quidoz   


*  [UUID avec PostgreSQL : Pourquoi ? Comment ?](http://rbdd.cnrs.fr/IMG/pdf/uuid_postgres.pdf?405/e6315023727441ee71c5d63415dd28285bc24952)   
. Raidelet   

*  [Les avantages et les inconvénients de la solution ODK](http://rbdd.cnrs.fr/IMG/pdf/bilan_odk.pdf?579/014d2664a47a1b155dde7a4ce7cf84db388194fa)  
   MC. Quidoz \& PY. Arnould \& les stagiaires   

*  [Référence sur ODK](http://rbdd.cnrs.fr/IMG/pdf/bibliographie.pdf?571/bbecc7bd883e4751efb6ccba6f99517ded5a6305) 
MC. Quidoz   

*  [Outils nomades : validation des données](http://rbdd.cnrs.fr/IMG/pdf/anf_rbbd_2019_outils_mobiles_tp_qualite.pdf?573/e1425561fd10c6bd1dd92fdee22871bc427f9873)    
C. Plumejeaud   

*  [Retour terrain : la délicate question de l’intégration des données](http://rbdd.cnrs.fr/IMG/pdf/anf2019_seshat.pdf?576/575888582b8771a01200c5a6a5e751f0964e0c33)   
PY. Arnould   



### La gestion des collections 

[Collec-Science](https://www.collec-science.org) est un logiciel web qui a été créé pour suivre les échantillons collectés lors des campagnes d’acquisition, et permet de répondre, entre autres, à ces questions :
-  où est stocké l’échantillon ?
-  d’où vient-il, quelle est sa généalogie (protocole de collecte, métadonnées associées à l’échantillon et ceux de ces ancêtres) ?
-  quelles transformations ou opérations a-t-il subies ?
-  sous quelle forme est-il conservé, existe-t-il un risque à le manipuler ?

Fruit d’une collaboration initiale entre Irstea (centre de Bordeaux), le laboratoire Epoc à Bordeaux, le LIENSs à La Rochelle, il a été enrichi avec la participation de nombreux autres laboratoires, dont les laboratoires Chrono-environnement à Besançon, Edytem à l’Université Savoie - Mont Blanc, etc. Il a été choisi par le Réseau des Zones Ateliers pour assurer le suivi des échantillons.

* [Stockez et retrouvez vos échantillons avec Collec-Science](http://rbdd.cnrs.fr/spip.php?article304)   
Marie-Claude Quidoz   
