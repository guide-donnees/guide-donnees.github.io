# 4. Traiter

*Contexte: Cette étape du cycle de vie des données est destinée à Filtrer, regrouper, choisir les données pertinentes, reformater, gérer les métadonnées : Les réseaux participent au traitement des jeux de données via la mise en place de procédures ou logiciels assurant la qualité des données et la qualité des traitements (modélisation et reformatage des données ; mise en base de données ; mise à disposition de moyens informatiques; aide aux choix de la solution la plus adaptée, détection des erreurs de saisie ou des incohérences relatives aux modèles de données, mise en place d’un contrôle qualité)*


## Chaines et méthodes de traitement de données



### Logiciels  et plateforme logicielles de traitement

   * Introduction au langage de programmation Julia et son utilisation dans le cadre du traitement de données. Journée Julia, Map Reduce, janvier 2019
       * <https://calcul.math.cnrs.fr/2019-01-journee-julia.html#collapseSupports1>
           * Xavier Vasseur, ISAE

   * Python et l'écosystème disponible pour la data science
       *   <https://calcul.math.cnrs.fr/2017-12-journee-python-data.html>

Des logiciels sont plus particulièrement adaptés dans la diffusion et d'affichage des données scientifiques d'observation, de plus en utilisant les standards ineropérables
de l'Open Geospatial Consortium (OGC), ISO19139, Inspire, etc)

    

    
*  le serveur cartographique *Geoserver* permet d'afficher et permettre les échanges de données géospatiales sur le web selon les standards (WMS, WFS, ...) de l'OGC ;
    

*  le logiciel *GeoNetwork* permet de  cataloguer les métadonnées de jeux de données selon la norme ISO 19139 et la directive Inspire;
    
*  l'application GeoCMS permettant la visualisation de données géospatiales sur le web et de mettre en place une Infrastructure de Données Géographique (IDG) 
    
*  Les logiciels comme Thredds et Erddap sont des plateforme web de gestion qui permettent une gestion FAIR pour la diffusion des données 

*  L'utilisation de ce slogiciels fait l'objet d'une  Action  nationale de formation du réseau SIST http://sist.cnrs.fr qui permet de savoir installer, configurer et utilsier ces logiciels
   *  https://sist.cnrs.fr/les-formations/supports-des-anf-gestion-de-donnees-dobservation


### Traitement de fichiers - Format de fichiers interopérables

   * mise en forme des données dans des formats interopérables NetCDF, ODV, HDF, etc..

   * Copier les succès et rester simple (AMEO) : Mise à disposition de sorties de modèles climatiques avec un NAS, THREDDS et ERDDAP.                                      
       * <https://sist16.sciencesconf.org/data/pages/11\_T\_Valero\_F\_Bongat.pdf>
           *  - Thierry VALERO, Institut de Recherche pour le Développement, Laboratoire   d'Océanographie et du Climat : Expérimentations et Approches Numérique
              * <https://sist16.sciencesconf.org/data/pages/12\_R\_Hocde.pdf>

   * Réseau d'observation du Pacifique Sud ‘ReefTEMPS' : évolutions fonctionnelles et optimisation d'un système d'information dédié capteurs et reconstitution de séries temporelles                   
       *   <https://sist16.sciencesconf.org/data/pages/12\_R\_Hocde.pdf>                     
           * - Régis Hocdé, Institut de Recherche pour le Développement

Le format de fichier NetCDF https://www.unidata.ucar.edu/software/netcdf/
est particulièrement interessant pour stocker et représenter des données qui sont des séries temporelles, des profils verticaux ou des trasjectoires.
Il est très utilisé en sciences de l'environnement par exemple en océanographie, météorologie, atmosphere.
Ce format présente l'avantage d'etre autodocumenté grace une entete qui permet d'inscrire un grand nombre de métadonnées dans le ficheir lui même.
Ainsi les métadonnées sont embarquées et véhiculées dans le fichier avec les données eles memes.
On peut ainsi connaitre les unités des données, la licence, les proprietaires etc, ainsi que l'organisation des données, sans avoir besoin d'un fichier de description complémentaire.

* présentation du format NetCDF
  * https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_JS.pdf
* La convention CF (climate forecast) pour les fichiers NetCDF
  * https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_CF_ML.pdf
* utilisation de l'API de programmatino Python pour NetCDF
  * https://sist19.sciencesconf.org/data/pages/SIST19_Atelier_NetCDF_python.pdf


Le format ODV (ocean data view) https://odv.awi.de/  est également un format intéressant. Il se rapproche d'un format CSV i.e des colonnes de données séparées par des virgules (ou tout autre séparateur)
à cette différence près que le format ODV prévoie l'insertion d'une entete assez riche permettant de placer des métadonnées

Les formats NetCDF et ODV sont des formats recommandés et utilisés par le pôle de données Odatis et par le projet Européen Seadatanet.


### Curation des données

*[il faudra expliciter le terme et les concepts svp] = organiser /traiter différents éléments d'une même collection pour mieux la diffuser, la valoriser c a d commenter, annoter, décrire etc...*
JJ : pour moi la curation des données englobe tous les aspects pris en compte par les différents points du guide. La curation est un tout.

« Les activités de curation de données permettent de faciliter la découverte et la récupération de données, de maintenir la qualité des données, de leur ajouter de la valeur et d’en fournir pour de futures réutilisations. Ce nouveau champ inclut la représentation, l’archivage, ’authentification, la gestion, la préservation, la récupération, et l’utilisation. »
Digital Humanities Data Curation


**« De quelques défis spécifiques de la curation numérique des données en SHS : petite incursion dans l’univers de l’édition critique de sources au format TEI »**
* Emmanuelle Morlock, HiSoMa)
* Frédocs2013 - Gestion et valorisation des données de la recherche -  7 au 10 octobre 2013, Aussois     
* http://renatis.cnrs.fr/IMG/pdf/emma-morlock-fredocs-2013

Cette présentation s’organise en trois parties : les spécificités de la **« data curation »**, les d**éfis spécifiques aux SHS** et ce que la **TEI** propose pour les relever 
à travers l’exemple de l’**encodage de sources textuelles**. Dans un  premier temps Emmanuelle Morlock définit la **notion de curation**, les notions qui gravitent autour 
et celle de data curation. Elle présente les **activités transversales associées à la curation des données** et l**es défis que cela représente pour les sciences humaines 
et sociales**. Elle s’intéresse ensuite aux **types d’objets de la curation**, les difficultés associées. Elle aborde ensuite le chapitre de l’**édition savante** en précisant 
qu’il s’agit de bien plus qu’une simple reproduction augmentée, indiquant par exemple qu’il convient là de garantir la fiabilité et la lisibilité du texte, de mettre 
en forme un dispositif de lecture en fonction des attentes et des conventions d’un lectorat donné, de faire des choix etc … **Le numérique** apporte à ce stade un certain 
nombre de **promesses** (démultiplie les interfaces de lecture et les possibilité de navigation) mais connait aussi **ses limites** (demande des investissements, des compétences 
spécifiques en encodage, structuration etc.). Ceci l’amène à définir précisément ce qu’est l’**édition numérique** (un texte enrichi, exploitable par des machines) et à 
présenter, définir et expliquer le **processus d’édition dans un format XML TEI**. Elle explique aussi l’apport de la TEI dans la réponse aux défis posés par l’édition 
numérique (distinction de niveaux d’interprétation via le balisage, conservation et documentation des choix de manière formalisée) et termine sa présentation sur le 
**rôle des « curateurs** » pour répérer les manques dans un objectif de réutilisation à long terme ou pour aider les chercheurs à améliorer leurs pratique de documentation 
de leurs données.

*Voir si on place ici la présentation de soizick lesteven ou plus haut dans retours d’expérience*
  

## Métrologie des équipements

La confiance dans la qualité d’un recherche consiste à établir et vérifier que les différentes étapes d’une étude peuvent être répétées en obtenant le même résultat par des chercheurs différents à des moments différents. De ca fait, il convient d'avoir une totale maitrise des équipements de traitement :

   * Métrologie des équipements : <https://qualsimp.sciencesconf.org/data/program/9\_Trac\_abilite\_des\_donne\_es\_de\_la\_recherche\_Virginie\_JAN\_LOGASSI.pdf>    

## Contrôle Qualité des données - Mise en place de procédures qualité


   * Plusieurs présentations et ateliers sur ce thème ont eu lieu lors de l'ANF « Sciences des données : un nouveau challenge pour les métiers liés aux bases de données »(<http://rbdd.cnrs.fr/spip.php?article288)> - du 5 au 7 novembre 2018 à Sète. En particulier l'Atelier qualité des données dont les travaux portaient sur les questions suivantes : 
       * Quelles sont les différentes notions de **qualité** des données ?
       * Comment contrôler la **qualité** des données dans la BDD : avant ou pendant l’insertion de données
       * Faut-il automatiser le contrôle de la qualité dans les bases ?
       * Quels sont les outils disponibles et comment les utiliser ?    L'Introduction méthodologique et terminologique (<http://rbdd.cnrs.fr/IMG/pdf/qualite\_des\_donnees\_plumejeaud\_2018\_04112018.pdf?517/365a13edab604bd0700b045bfac29a3607acb649)> a été suivie d'un cours et de TP portant sur "OpenRefine pour traiter son fichier d’entrée" (<http://rbdd.cnrs.fr/IMG/pdf/openrefinecours.pdf?518/a69ce451abd02003a0e96957e39828e0f2e9f2ee> , <http://rbdd.cnrs.fr/IMG/pdf/openrefinedoc.pdf?519/a6de5321fdbedeec29da6cc8b82250d02937ddeb> , <http://rbdd.cnrs.fr/IMG/zip/exos.zip?520/e51f82826431b71f767e4347fd57716fa9175664> )
    On pourra aussi de référer à quelques présentations de l''ANF « Interfacer les outils mobiles avec son système d’information » citée au chapitre 3 (Collecter) :

       *  Outils nomades : validation des données (C. Plumejeaud) (<http://rbdd.cnrs.fr/IMG/pdf/anf\_rbbd\_2019\_outils\_mobiles\_tp\_qualite.pdf?573/e1425561fd10c6bd1dd92fdee22871bc427f9873)>
       *  Retour terrain : la délicate question de l’intégration des données (PY. Arnould) (<http://rbdd.cnrs.fr/IMG/pdf/anf2019\_seshat.pdf?576/575888582b8771a01200c5a6a5e751f0964e0c33)>

   * BLONDEL, Emmanuel, 2018. Ecrire et Lire des métadonnées avec la librairie R geometa. In : *Atelier « Métadonnées et R »*. Montpellier. 2018. <http://rbdd.cnrs.fr/IMG/pdf/workshop\_r\_metadata\_agropolis\_-\_geometa.pdf?504/f5cc31589976b1cd1fc18d406a547ee18122c0e7>


   * [resinfo] Traitement de grosses masses de données (BigData), regroupement de données, filtrage et extraction des données pertinentes (ANF 2016)
   * <https://indico.mathrice.fr/event/5/contribution/19/material/slides/0.pdf>



